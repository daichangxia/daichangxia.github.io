<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Nginx十万并发配置]]></title>
    <url>%2F2019%2F04%2F19%2FNginx%E5%8D%81%E4%B8%87%E5%B9%B6%E5%8F%91%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx 数十万并发设置[ ](1.png)## 1.系统参数1234567891011121314151617[root@node101 ~]# ulimit -a core file size (blocks, -c) 0 #core文件的最大值为100 blocks。data seg size (kbytes, -d) unlimited #进程的数据段可以任意大。scheduling priority (-e) 0 #指定调度优先级file size (blocks, -f) unlimited #文件可以任意大。pending signals (-i) 31152 #最多有31152个待处理的信号。max locked memory (kbytes, -l) 64 #一个任务锁住的物理内存的最大值为64KB。max memory size (kbytes, -m) unlimited #一个任务的常驻物理内存的最大值。open files (-n) 1024 #一个任务最多可以同时打开1024的文件。pipe size (512 bytes, -p) 8 #管道的最大空间为4096字节。POSIX message queues (bytes, -q) 819200 #POSIX的消息队列的最大值为819200字节。real-time priority (-r) 0 #指定实时优先级stack size (kbytes, -s) 8192 #进程的栈的最大值为8192字节。cpu time (seconds, -t) unlimited #进程使用的CPU时间。max user processes (-u) 31152 #当前用户同时打开的进程（包括线程）的最大个数为31152。virtual memory (kbytes, -v) unlimited #没有限制进程的最大地址空间。file locks (-x) unlimited #所能锁住的文件的最大个数没有限制。 2.nginx参数调优worker进程数是否合理1worker_processes auto; nginx worker进程数量，建议和cpu核数相当. 分析: worker_processes是worker进程的数量，默认值为auto，这个优化值受很多因素的影响，如果不确定的话，将其设置为CPU内核数是一个不错的选择 worker连接数是否合理1worker_connections 1024; 单个worker进程可服务的客户端数量（根据并发要求进行更改） 分析:worker_connections 设置了一个worker进程可以同时打开的链接数，有高并发需求时，按照需求进行设定。链接最大数目= worker_processes * worker_connections worker可打开最大文件数是否合理1worker_rlimit_nofileulimit -n Nginx 最大可用文件描述符数量linux可同时打开最大文件数 分析:worker_rlimit_nofile为Nginx单个worker进程最大可用文件描述符数量，和链接数相同；最大数目= worker_processes * worker_rlimit_nofile。 同时需要配置操作系统的 “ulimit -n XXXX”，或者在 /etc/security/limits.conf 中配置。 来达到对应配置。 配置数量按照需求情况设定，不建议配置较高的值。 multi_accept1multi_accept on; 是否尽可能的接受请求（建议打开） 分析: multi_accept 的作用是告诉 nginx 在收到新链接的请求通知时，尽可能接受链接。当然，得让他开着。 读写方式是否合理1sendfile on; 直接从磁盘上读取数据到操作系统缓冲（建议打开） 分析: ​ 在 sendfile 出现之前，为了传输这样的数据，需要在用户空间上分配一块数据缓存，使用 read() 从源文件读取数据到缓存，然后使用 write() 将缓存写入到网络。 sendfile() 直接从磁盘上读取数据到操作系统缓冲。由于这个操作是在内核中完成的，sendfile() 比 read() 和 write() 联合使用要更加有效率。 tcp_nopush1tcp_nopush on; 在一个包中发送全部头文件（建议打开,默认为打开状态） 分析: 配置 nginx 在一个包中发送全部的头文件，而不是一个一个发送。这个选项使服务器在 sendfile 时可以提前准备 HTTP 首部，能够达到优化吞吐的效果。 tcp_nodelay1tcp_nodelay on; 配置 nginx 不缓存数据，快速发送小数据 分析: 不要缓存 data-sends （关闭 Nagle 算法），这个能够提高高频发送小数据报文的实时性。系统存在高频发送小数据报文的时候，打开它。 客户端在keep-alive的请求数量是否合理1keepalive_requests 100000; 建议配置较大的值 分析: 设置通过”一个存活长连接”送达的最大请求数（默认是100，建议根据客户端在”keepalive”存活时间内的总请求数来设置）当送达的请求数超过该值后，该连接就会被关闭。（通过设置为5，验证确实是这样）建议设置为一个较大的值 客户端通信超时时间是否合理1keepalive_timeout 65; 超时时间. 分析: ​ 配置连接 keep-alive 超时时间，服务器将在超时之后关闭相应的连接。 指定了与客户端的 keep-alive 链接的超时时间。服务器会在这个时间后关闭链接。 keep-alive设置过小客户端和服务器会频繁建立连接；设置过大由于连接需要等待keep-alive才会关闭，所以会造成不必要的资源浪费。 后端服务器超时时间是否合理12345proxy_connect_timeout //默认60sproxy_read_timeout //默认60sproxy_send_timeout //默认60s 默认60s 分析: proxy_connect_timeout :后端服务器连接的超时时间_发起握手等候响应超时时间 proxy_read_timeout:连接成功后等候后端服务器响应时间其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_send_timeout :后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 reset_timedout_connection配置是否合理1reset_timedout_connection on; 服务器在客户端停止发送应答之后关闭连接. 分析: ​ 允许server在client停止响应以后关闭连接,释放分配给该连接的内存。当有大并发需求时，建议打开。 request body读超时时间是否合理1client_body_timeout 10; 默认60s. 分析; 该指令设置请求体（request body）的读超时时间。仅当在一次readstep中，没有得到请求体，就会设为超时。超时后，nginx返回HTTP状态码408(“Request timed out”) types_hash_max_size1types_hash_max_size 2048; types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 分析; ​ ypes_hash_max_size影响散列表的冲突率。types_hash_max_size越大，就会消耗更多的内存，但散列key的冲突率会降低，检索速度就更快。types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 日志记录是否合理1access_log /var/log/nginx/access.log main; #默认打开 access_log和error_logaccess_log建议关闭，降低磁盘IO提高速度error_log 压缩选用是否合理1234567# nginx默认不进行压缩处理 gzip on; gzip_disable &quot;msie6&quot;; gzip_proxied any; gzip_comp_level 9; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;设置数据压缩设置禁止压缩是否压缩基于请求、响应的压缩压缩等级压缩类型 gzip ：设置nginx gzip压缩发送的数据，建议打开 gzip_disable：为指定的客户端禁用gzip功能，(IE5.5和IE6 SP1使用msie6参数来禁止gzip压缩 )指定哪些不需要gzip压缩的浏览器(将和User-Agents进行匹配),依赖于PCRE库 gzip_proxied：Nginx作为反向代理的时候启用，根据某些请求和应答来决定是否在对代理请求的应答启用gzip压缩，是否压缩取决于请求头中的“Via”字段，指令中可以同时指定多个不同的参数，意义如下（ 无特殊需求建议设置为any）： off(关闭所有代理结果的数据的压缩) expired - 启用压缩，如果header头中包含 “Expires” 头信息 no-cache - 启用压缩，如果header头中包含 “Cache-Control:no-cache” 头信息 no-store - 启用压缩，如果header头中包含 “Cache-Control:no-store” 头信息 private - 启用压缩，如果header头中包含 “Cache-Control:private” 头信息 no_last_modified - 启用压缩,如果header头中不包含 “Last-Modified” 头信息 no_etag - 启用压缩 ,如果header头中不包含 “ETag” 头信息 auth - 启用压缩 , 如果header头中包含 “Authorization” 头信息 any - 无条件启用压缩 gzip_comp_level：数据压缩的等级。等级可以是 1-9 的任意一个值，9 表示最慢但是最高比例的压缩 gzip_types：设置进行 gzip 的类型；对于多数以文本为主的站点来说，文本自身内容占流量的绝大部分。虽然单个文本体积并不算大，但是如果数量众多的话，流量还是相当可观。启用GZIP以后，可以大幅度减少所需的流量. linux系统是否启用epoll1use epoll; Linux 关键配置，允许单个线程处理多个客户端请求。 分析: ​ Linux 关键配置，允许单个线程处理多个客户端请求。 缓存设置是否合理1234567open_file_cache max=200000 inactive=20s;//缓存最大数目及超时时间检测open_file_cache_valid 30s; //缓存源文件是否超时的间隔时间open_file_cache_min_uses 2;//缓存文件最小访问次数open_file_cache_errors on;//缓存文件错误信息 3.服务器内核参数调优net.ipv4.tcp_max_tw_buckets = 6000 timewait 的数量，默认是180000。 net.ipv4.ip_local_port_range = 1024 65000 允许系统打开的端口范围。 net.ipv4.tcp_tw_recycle = 1 启用timewait 快速回收。 net.ipv4.tcp_tw_reuse = 1 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。 net.ipv4.tcp_syncookies = 1 开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。 net.core.somaxconn = 262144 web 应用中listen 函数的backlog 默认会给我们内核参数的net.core.somaxconn 限制到128，而nginx 定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。 net.core.netdev_max_backlog = 262144 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 net.ipv4.tcp_max_orphans = 262144 系统中最多有多少个TCP 套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_max_syn_backlog = 262144 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。 net.ipv4.tcp_timestamps = 0 时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 1 为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。 net.ipv4.tcp_syn_retries = 1 在内核放弃建立连接之前发送SYN 包的数量。 net.ipv4.tcp_fin_timeout = 1 如 果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。 net.ipv4.tcp_keepalive_time = 30 当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。 4.nginx.conf配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869user root;# cpu数量，建议使用默认worker_processes auto;pid /run/nginx.pid;# 配置nginx worker进程最大打开文件数 worker_rlimit_nofile 65535;events &#123; # 单个进程允许的客户端最大连接数 worker_connections 20480; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable "msie6"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; 5.内核配置文件1234567891011121314151617181920212223242526272829303132net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 262144net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65000 vi /etc/sysctl.conf CentOS5.5中可以将所有内容清空直接替换. 使配置立即生效可使用如下命令：/sbin/sysctl -p 6.系统连接数linux 默认值 open files 和 max user processes 为 1024 #ulimit -n 1024 #ulimit Cu 1024 问题描述： 说明 server 只允许同时打开 1024 个文件，处理 1024 个用户进程 使用ulimit -a 可以查看当前系统的所有限制值，使用ulimit -n 可以查看当前的最大打开文件数。 新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files 。因此，需要将其改大。 解决方法： 使用 ulimit Cn 65535 可即时修改，但重启后就无效了。（注ulimit -SHn 65535 等效 ulimit -n 65535 ，-S 指soft ，-H 指hard) 有如下三种修改方式： \1. 在/etc/rc.local 中增加一行 ulimit -SHn 65535 2. 在/etc/profile 中增加一行 ulimit -SHn 65535 3. 在/etc/security/limits.conf 最后增加： 1234* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 具体使用哪种，在 CentOS 中使用第1 种方式无效果，使用第3 种方式有效果，而在Debian 中使用第2 种有效果 # ulimit -n 65535 # ulimit -u 65535 备注：ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制 soft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。 soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值。]]></content>
      <categories>
        <category>Nginx</category>
        <category>Nginx十万并发</category>
      </categories>
      <tags>
        <tag>Nginx并发配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置介绍]]></title>
    <url>%2F2019%2F04%2F19%2FNginx%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Nginx配置信息详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327#nginx进程,一般设置为和cpu核数一样,使用auto将自动配置worker_processes 4; #错误日志存放目录 error_log /data/logs/error.log crit; #运行用户，默认即是nginx，可不设置user nginx #进程pid存放位置pid /application/nginx/nginx.pid; #Specifies the value for maximum file descriptors that can be opened by this process. #最大文件打开数（连接），可设置为系统优化后的ulimit -HSn的结果worker_rlimit_nofile 51200;#cpu亲和力配置，让不同的进程使用不同的cpuworker_cpu_affinity 0001 0010 0100 1000 0001 00100100 1000;#工作模式及连接数上限events &#123; use epoll; #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能 worker_connections 1024; #;单个后台worker process进程的最大并发链接数&#125;http &#123;include mime.types; #文件扩展名与类型映射表default_type application/octet-stream; #默认文件类型#limit模块，可防范一定量的DDOS攻击#用来存储session会话的状态，如下是为session分配一个名为one的10M的内存存储区，限制了每秒只接受一个ip的一次请求 1r/s limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; limit_conn_zone $binary_remote_addr zone=addr:10m; include mime.types; default_type application/octet-stream;#第三方模块lua防火墙 lua_need_request_body on; #lua_shared_dict limit 50m; lua_package_path &quot;/application/nginx/conf/waf/?.lua&quot;; init_by_lua_file &quot;/application/nginx/conf/waf/init.lua&quot;; access_by_lua_file &quot;/application/nginx/conf/waf/access.lua&quot;; #设定请求缓存 server_names_hash_bucket_size 128; client_header_buffer_size 512k; large_client_header_buffers 4 512k; client_max_body_size 100m; #隐藏响应header和错误通知中的版本号 server_tokens off; #开启高效传输模式 sendfile on; #激活tcp_nopush参数可以允许把httpresponse header和文件的开始放在一个文件里发布,积极的作用是减少网络报文段的数量,tcp_nopush = on 会设置调用tcp_cork方法，这个也是默认的，结果就是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞。对于nginx配置文件中的tcp_nopush，默认就是tcp_nopush,不需要特别指定，这个选项对于www，ftp等大文件很有帮助. tcp_nopush on; #激活tcp_nodelay，内核会等待将更多的字节组成一个数据包，从而提高I/O性能.TCP_NODELAY和TCP_CORK基本上控制了包的“Nagle化”，Nagle化在这里的含义是采用Nagle算法把较小的包组装为更大的帧。Nagle化后来成了一种标准并且立即在因特网上得以实现。它现在已经成为缺省配置了. # 现在让我们假设某个应用程序发出了一个请求，希望发送小块数据。我们可以选择立即发送数据或者等待产生更多的数据然后再一次发送两种策略。如果我们马上发送数据，那么交互性的以及客户/服务器型的应用程序将极大地受益。如果请求立即发出那么响应时间也会快一些。以上操作可以通过设置套接字的TCP_NODELAY = on 选项来完成，这样就禁用了Nagle 算法。 另外一种情况则需要我们等到数据量达到最大时才通过网络一次发送全部数据，这种数据传输方式有益于大量数据的通信性能，典型的应用就是文件服务器。应用 Nagle算法在这种情况下就会产生问题。但是，如果你正在发送大量数据，你可以设置TCP_CORK选项禁用Nagle化，其方式正好同 TCP_NODELAY相反（TCP_CORK和 TCP_NODELAY是互相排斥的）。 tcp_nodelay on; #FastCGI相关参数：为了改善网站性能：减少资源占用，提高访问速度fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#连接超时时间，单位是秒 keepalive_timeout 60; #开启gzip压缩功能 gzip on； #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取。默认值是0，表示不管页面多大都进行压缩。建议设置成大于1K。如果小于1K可能会越压越大。 gzip_min_length 1k;#压缩缓冲区大小。表示申请4个单位为16K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。 gzip_buffers 4 16k;#压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。 gzip_http_version 1.0;#压缩比率。用来指定GZIP压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度快，但处理最慢，也比较消耗cpu资源。 gzip_comp_level 9;#用来指定压缩的类型，“text/html”类型总是会被压缩 gzip_types text/plain application/x-javascript text/css application/xml; #vary header支持。该选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过Nginx压缩的数据。gzip_vary off;#开启ssi支持，默认是off ssi on; ssi_silent_errors on;#设置日志模式 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;#反向代理负载均衡设定部分#upstream表示负载服务器池，定义名字为backend_server的服务器池upstream backend_server &#123; server 10.254.244.20:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.242.40:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.245.19:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.243.39:81 weight=1 max_fails=2 fail_timeout=30s; #设置由 fail_timeout 定义的时间段内连接该主机的失败次数，以此来断定 fail_timeout 定义的时间段内该主机是否可用。默认情况下这个数值设置为 1。零值的话禁用这个数量的尝试。设置在指定时间内连接到主机的失败次数，超过该次数该主机被认为不可用。#这里是在30s内尝试2次失败即认为主机不可用！ &#125;####################基于域名的虚拟主机 server &#123;#监听端口 listen 80; server_name www.abc.com abc.com; index index.html index.htm index.php; #首页排序 root /data0/abc; #站点根目录，即网站程序存放目录 error_page 500 502 404 /templates/kumi/phpcms/404.html; #错误页面#伪静态 将www.abc.com/list....html的文件转发到index.php。。。#rewrite ^/list-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\.html$ /index.php?m=content&amp;c=index&amp;a=lists&amp;catid=$1&amp;types=$2&amp;country=$3&amp;language=$4&amp;age=$5&amp;startDate=$6&amp;typeLetter=$7&amp;type=$8&amp;page=$9 last;#location 标签，根目录下的.svn目录禁止访问 location ~ /.svn/ &#123; deny all; &#125; location ~ \.php$ &#123; #符合php扩展名的请求调度到fcgi server fastcgi_pass 127.0.0.1:9000; #抛给本机的9000端口 fastcgi_index index.php; #设定动态首页 include fcgi.conf; &#125; allow 219.237.222.30 ; #允许访问的ip allow 219.237.222.31 ; allow 219.237.222.32 ; allow 219.237.222.33 ; allow 219.237.222.34 ; allow 219.237.222.35 ; allow 219.237.222.61 ; allow 219.237.222.28 ; deny all; #禁止其他ip访问 &#125; location ~ ^/admin.php &#123; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fcgi.conf; &#125; allow 219.237.222.30 ; allow 219.237.222.31 ; allow 219.237.222.32 ; allow 219.237.222.33 ; allow 219.237.222.34 ; allow 219.237.222.35 ; allow 219.237.222.61; allow 219.237.222.28; deny all; &#125;#将符合js,css文件的等设定expries缓存参数，要求浏览器缓存。location~ .*\.(js|css)?$ &#123; expires 30d; #客户端缓存上述js,css数据30天 &#125;##add by 20140321#######nginx防sql注入#############start####if ( $query_string ~* &quot;.*[\;&apos;\&lt;\&gt;].*&quot; )&#123; return 444; &#125;if ($query_string ~* &quot;.*(insert|select|delete|update|count|\*|%|master|truncate|declare|\&apos;|\;|and|or|\(|\)|exec).* &quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;(cost\()|(concat\()&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]union[+|(%20)]&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]and[+|(%20)]&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]select[+|(%20)]&quot;) &#123; return 444; &#125;set $block_file_injections 0;if ($query_string ~ &quot;[a-zA-Z0-9_]=(\.\.//?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($query_string ~ &quot;[a-zA-Z0-9_]=/([a-z0-9_.]//?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($block_file_injections = 1) &#123;return 448;&#125;set $block_common_exploits 0;if ($query_string ~ &quot;(&lt;|%3C).*script.*(&gt;|%3E)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;GLOBALS(=|\[|\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;_REQUEST(=|\[|\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;proc/self/environ&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;mosConfig_[a-zA-Z_]&#123;1,21&#125;(=|\%3D)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;base64_(en|de)code\(.*\)&quot;) &#123;set $block_common_exploits 1;&#125;if ($block_common_exploits = 1) &#123;return 444;&#125;set $block_spam 0;if ($query_string ~ &quot;\b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(erections|hoodia|huronriveracres|impotence|levitra|libido)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(ambien|blue\spill|cialis|cocaine|ejaculation|erectile)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(lipitor|phentermin|pro[sz]ac|sandyauer|tramadol|troyhamby)\b&quot;) &#123;set $block_spam 1;&#125;if ($block_spam = 1) &#123;return 444;&#125;set $block_user_agents 0;if ($http_user_agent ~ &quot;Wget&quot;) &#123; set $block_user_agents 1;&#125;# Disable Akeeba Remote Control 2.5 and earlierif ($http_user_agent ~ &quot;Indy Library&quot;) &#123;set $block_user_agents 1;&#125;# Common bandwidth hoggers and hacking tools.if ($http_user_agent ~ &quot;libwww-perl&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetRight&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetWeb!&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go!Zilla&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Download Demon&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go-Ahead-Got-It&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;TurnitinBot&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GrabNet&quot;) &#123;set $block_user_agents 1;&#125;if ($block_user_agents = 1) &#123;return 444;&#125;###end#### location ~ ^/list &#123; #如果后端的服务器返回502、504、执行超时等错误，自动将请求转发到upstream负载均衡池中的另一台服务器，实现故障转移。 proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_cache cache_one; #对不同的HTTP状态码设置不同的缓存时间 proxy_cache_valid 200 301 302 304 1d; #proxy_cache_valid any 1d; #以域名、URI、参数组合成Web缓存的Key值，Nginx根据Key值哈希，存储缓存内容到二级缓存目录内 proxy_cache_key $host$uri$is_args$args; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_ignore_headers &quot;Cache-Control&quot; &quot;Expires&quot; &quot;Set-Cookie&quot;; #proxy_ignore_headers Set-Cookie; #proxy_hide_header Set-Cookie; proxy_pass http://backend_server; add_header Nginx-Cache &quot;$upstream_cache_status from km&quot;; expires 1d; &#125; access_log /data1/logs/abc.com.log access; #nginx访问日志 &#125;-----------------------ssl（https）相关------------------------------------server &#123; listen 13820; #监听端口 server_name localhost; charset utf-8; #gbk,utf-8,gb2312,gb18030 可以实现多种编码识别 ssl on; #开启ssl ssl_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/server.crt; #服务的证书 ssl_certificate_key /ls/app/nginx/conf/mgmtxiangqiankeys/server.key; #服务端key ssl_client_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/ca.crt; #客户端证书 ssl_session_timeout 5m; #session超时时间 ssl_verify_client on; # 开户客户端证书验证 ssl_protocols SSLv2 SSLv3 TLSv1; #允许SSL协议 ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; #加密算法 ssl_prefer_server_ciphers on; #启动加密算法 access_log /lw/logs/nginx/dataadmin.test.com.ssl.access.log access ; #日志格式及日志存放路径 error_log /lw/logs/nginx/dataadmin.test.com.ssl.error.log; #错误日志存放路径&#125;-------------------------------------------------------------------------&#125;]]></content>
      <categories>
        <category>Nginx</category>
        <category>Nginx配置详解</category>
      </categories>
      <tags>
        <tag>Nginx配置详解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的回收和分配]]></title>
    <url>%2F2019%2F03%2F17%2F%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9E%E6%94%B6%E5%92%8C%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[GC算法 2019年3月17日 12:32 简介:由内存模型可知,虚拟机栈,本地方法栈,程序计数器都是线程私有的,伴随着线程的结束而消失.其中虚拟机栈和本地方法栈中的栈桢也会随着方法的进入和退出而进行着入栈和出栈的操作.每一个栈桢需要的内存基本上是在类结构确定下来后就确定了.因此内存的回收和分配都具有确定性,因此不需要过多考虑.但是在java堆和方法区,由于是动态加载,只有在运行期才会知道需要分配和回收的内存.因此,垃圾回收器所关注的也是这部分的内存. 判断对象已死?要进行对象回收首先要确定对象是否已死,目前有以下几种方式: 1. 引用计数算法:为每个对象添加一个引用计数器,每有一个地方引用,就加1,引用失效就减1.当为0时,则判为死亡.此方法在两个对象相互引用时,无法用此算法清除. 2. 根搜索算法:通过一个GC root的根节点,往下搜索,如果搜索不到,则为死亡. 在java中,可作为GC roots的对象有: a. 虚拟机栈中的栈桢下面的局部变量表所引用的对象. b. 方法区中静态类属性所引用的对象. c. 方法区中的常量所引用的对象. d. 本地方法栈中native方法所引用的对象. 3. java中的引用a. 强引用: 例如:Object obj= new Object();只要引用还存在,永远不会GC. b. 软引用: 用SoftReference类来实现,被软引用关联的对象,在内存溢出发生之前,会对这部分进行回收. c. 弱引用 用WeakReference类实现,无论是否会发生内存溢出,在GC的时候,都会清除. d. 虚引用 用PhantomReference类实现.唯一目的是在这些对象被回收之前,会得到一个系统通知, 4. Finallize()方法只会被系统调用一次,有不确定性,并且代价极大.建议用try-finally来代替. GC算法1. 标记-清除法首先标记出对象,然后统一回收.缺点是:效率低.并会产生大量不连续的内存碎片. 2. 复制法将内存分为两块,每次讲需要回收的对象放到一块,然后统一清理.缺点是:活跃内存减少一半,代价极大. 3. 复制法进阶版由于新生代对象具有极高的死亡率,因此将内存按照8:1的比例划分为一个大的Eden和2个小的survivor空间.每次使用的是Eden空间和一个survivor空间.在进行回收时,将或者的对象复制到那个暂时不用的survivor空间中.然后清理掉Eden空间和survivor空间.这样基本上只会浪费10%的内存空间.这种方式只适用于新生代. 4. 标记-整理算法​ 将或者的对象移动到一块,然后清理掉后面的对象.适用于老年代. 内存的分配策略:1. 新生代的Eden区分配大多数情况下,对象在新生代的Eden区分配,内存不足时,发起一次Minor GC 2. 大对象直接进入老年代.需要注意的是,避免编写短命的大对象. 3. 长期存活的对象直接进入老年代.每个对象都有一个年龄计数器(Age),在Eden出生,在第一次Minor GC下仍存活,并且被survivor所接受的话,就会移动到survivor中,年龄设为1.每次熬过一次Minor GC,年龄就加1,直到默认的15岁后,便会移动到老年代. 4. 动态对象年龄判断如果13岁的对象所占的空间大于survivor空间的一般,则会吧13的也放到老年代. 5. 空间分配担保当新生代在进行一个Minor GC后,仍有大量对象存活.将会将survivor空间无法容纳的对象直接进入老年代.在每次发生Minor GC 之前,都会检查之前每次晋升到老年代的平均大小,如果大于,便会改为一个Full GC.]]></content>
      <categories>
        <category>jvm</category>
        <category>对象的回收和分配</category>
      </categories>
      <tags>
        <tag>GC算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之内存模型]]></title>
    <url>%2F2019%2F03%2F17%2Fjvm%E4%B9%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[屏幕剪辑的捕获时间: 2019/3/16 10:56 注: 线程共享数据区:虚拟机栈,本地方法栈,程序计数器. 线程隔离数据区:方法区,堆,执行引擎,本地库接口. 简介:由于java将内存的管理交给了虚拟机,了解内存结构,有利于排查内存溢出和泄露问题. jdk1.8之后,hotspot的jvm: java整个进程占用的内存： 堆内存 metaspace(堆内) JDK8使用metaspace来替代了permsize:永久代大小 堆外内存使用 线程栈空间 jvm运行时的数据区域:程序计数器:\1. 一块很小的内存区域,主要作用是当前线程所执行字节码的行号指示器.字节码解释工作是,根据改变程序计数器的值来选取下一条所执行的字节码指令.例如:分支,循环,跳转,异常处理.因为jvm多线程是通过线程轮流切换来实现的,因此程序计数器是线程私有的. \2. 如果是正在执行java方法,此区域存储的是正在执行的虚拟机的字节码指令.如果是native方法,此区域为undefined.程序计数器是唯一一片不会出现outofmemoryerror的区域. java虚拟机栈\1. 描述的是方法的执行的内存模型,每一个方法的执行都会创建一个栈桢,用于存储局部变量表,操作数栈,动态链接,方法出口信息. \2. 局部变量表就是平常所说的栈,存储着编译期可知的基本数据类型,对象引用,returnAddress类型.基本单位是32个字节的slot,所需的空间在编译期就可以确定.常出现的异常:stackOverFlowError:请求的栈深度大于所允许的深度.OutMemoryError:虚拟机栈允许动态扩展的情况下,无法申请到足够的内存. 本地方法栈和虚拟机栈的区别是: 虚拟机栈是为java方法提供服务,而本地方法栈则是为了native方法提供服务. java堆(重点)\1. 是java虚拟机所管理的最大的一块内存区域.被所有线程共享.唯一目的是存放对象的实例.按照java虚拟机规范:堆中存放着所有的对象实例和数组信息.后续技术更加成熟也有稍微变化的地方. \2. java堆是垃圾收集器管理的主要区域.因此称为GC堆.按照内存回收方面看,可以分为新生代和老年代.永久代在哪?看下面的方法区.0.0 \3. java堆可以存放在不连续的内存空间,只要是逻辑上连续即可.当无法分配更多的实例时,会抛出OutOfMemoryError. 方法区\1. 主要是存放被虚拟机加载的类的信息,常量,静态变量,编译后的代码. \2. HotSpot虚拟机的设计团队选择了将GC分代管理扩展到了方法区,因此方法区就成了GC分代所说的永久代.这个区域很少有垃圾回收行为存在,但是也需要常量的回收和类型的卸载.不过次区域的回收,依旧是难点. 运行时的常量池\1. 运行期的常量池是方法区的一部分,用于存放编译期生成的字面量和符号引用. \2. 需要注意的是和局部变量表的局别.同样是存储编译期的数据,不过一个是方法的参数,方法内定义的变量.另一个是存储字面量的常量. 直接内存直接内存不是jvm的内存.是介于本地方法栈中的native方法,与java堆之间的一种机器中的内存.主要是在native方法进行io流的时候进行缓存数据的区域. 对象的访问在了解了虚拟机运行时候的数据区域后,下面来看下是如何进行对象访问的. 例如: Object obj = new Object(); 假设这块方法出现在方法体中,其中Object obj会映射到虚拟机栈的栈桢的局部变量表中的reference类型. new Object()则会映射到java堆中.另外java堆中还必须能够查到次对象类型的数据(对象的类型,父类,实现的接口,方法),这些数据存放在方法区.其中reference方法是如何定位到java堆中的?主要有2种方式: \1. 句柄池访问: 屏幕剪辑的捕获时间: 2019/3/16 12:38 在java堆中划分出一块内存作为句柄池,reference存储的是句柄池的地址.句柄池内存储着对象实例的数据和对象类型的数据. 主要优点是:对象进行移动时,只需要改变句柄池中的对象实例信息. \2. 直接指针访问方式 屏幕剪辑的捕获时间: 2019/3/16 12:41 reference存储的是对象实例的数据,这是就要考虑如何放置对象类型的数据的地址.主要优点是节省了一次指针的定位,速度更快.sun 的hotspot所用的虚拟机主要是采用此方案. OOM异常java堆溢出通过-Xms指定最小值,-Xmx指定最大值 提示是java heap space,查看对象信息,确定是否是要用的,如果对象必须要或者,则是内存溢出,此时加大虚拟机内存.如果对象不必须活着,则是内心泄露,此时定位到对象点,进行处理. 虚拟机栈和本地方法栈溢出通过-Xss128k,表示指定大小为128k,主要有2种异常 \1. 线程请求的深度大于虚拟机允许的最大深度:Stack OverflowError. \2. 虚拟机在扩展栈时,无法请求到足够的内存:OOM 运行时常量池溢出方法区内存,指定大小和方法区一致.提示信息是:PermGen space . 方法区溢出(1.8之后移除)通过-XX:PerSize和-XX:MaxPermSize指定大小,提示信息是:PermGen space ,方法区主要存储的是Class的信息,如类名,修饰符,常量池,字段描述,方法描述等.(1.8之后已经失效) 元空间在jdk1.8之后,hotspot对jvm架构进行了改变,将类的元数据放在了本地内存里面,静态变量和常量池放在了java堆中,移除了永久代,元数据是描述数据之间的关系的数据,其表现形式是1.5之后的注解,1.5之前的xml文件.由于在本地内存中,可以避免两个项目引用了同样的jar包,会出现大量的相同类信息引发的oom异常.避免了与老年代的资源竞争. 可用-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize指定元数据大小 本机直接内存溢出通过-XX:MaxDirectMemorySize指定大小,仅是抛出OOM溢出.]]></content>
      <categories>
        <category>jvm</category>
        <category>内存模型</category>
      </categories>
      <tags>
        <tag>java内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之字节码执行引擎]]></title>
    <url>%2F2019%2F03%2F04%2Fjvm%E4%B9%8B%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[概述从宏观上来说,java虚拟机的执行引擎基本上都是按照输入字节码,字节码解析,输出执行结果.从概念模型上来说,分为方法的调用和字节码的执行.下面详细描述: 运行时的栈桢结构2.1 简介栈桢是支持方法调用和字节码执行的数据结构.他是虚拟机运行时数据区的虚拟机栈的栈元素.栈桢存储着局部变量表,操作数栈,动态连接和方法返回地址等信息.每一个方法的调用到完成都对应着虚拟机栈的入栈到出栈的过程.在代码编译的时候,栈桢的深度就已经确定了,因此一个栈需要多少内存,不会受到运行期数据的影响. 在活动线程中,只有最顶层的当前栈桢是有效的.引擎中所有的字节码指令都是针对当前栈桢的. 2.2 局部变量表一组变量值存储空间.用于存放方法的参数和方法内部定义的变量.最小单位是slot.一个slot可以存放32位的数据类型,比如:short,byte,boolean,char,float,int,refearce(对象实例的引用).而对于64位的long和double,则会使用2个连续的slot来存储. 注意:java中的long和double都是非原子性的,在32位操作系统上,即读写都是分离的.每次读32位数据.因此在高并发性,需要volatile关键字标注. 但是在局部变量表里面,局部变量表是建立在线程的栈桢上,单线程私有,因此不会要安全问题. slot顺序: 虚拟机通过索引使用局部变量表.方法在执行时,第0位索引是当前实例变量的引用,即this关键字.其余则会按照顺序排序. 为节省栈桢空间,slot是可以重复使用的.即一个变量即使后续确定不再使用,则也不会立即回收其空间. 对一个变量赋值null使其被回收是没有意义的,因此在经过JIT编译器后,赋值null的操作会被清除掉. 局部变量表没有在类加载准备阶段对变量赋值,因此如果不赋值,会在编译期间报错. 2.3 操作数栈操作栈是一个先入后出的栈.可存储任意类型的数据.32位的栈容量为1,64位的为2.操作栈的深度不会超过max_stacks的值.在方法执行的时候,操作栈是空的,随着方法的执行,不断进行入栈和出栈操作. 例子:int a +int b ,在执行时a和b在栈顶的2个位置,然后字节码指令iadd,栈顶2个元素出栈,则会对其相加,然后将结果入栈. 在概念模型中,两个栈是独立的,但是虚拟机做了一些处理,2个栈可能会共享一部分数据.以便在调用方法时,无需再进行参数的复制传递.称之为:基于栈的执行引擎. 2.4 动态连接 每个栈桢都包含一个指向运行期常量池中该栈桢所属方法的引用.这个引用是为了动态连接. 2.5 方法返回地址 方法开始执行后,会有2条退出指令. ① 正常退出:遇到方法返回的字节码指令.栈桢中存储了PC计数器的值,作为返回地址 ② 异常退出: athrow 字节码指令.通过异常处理器表来确定返回地址. 方法调用方法调用不是方法执行,方法调用唯一的任务是确定调用那个方法.因为在编译阶段,没有连接过程,只是进行了符号引用,而没有真正分配内存布局的入口地址(直接引用).这个特性给java带来了强大的动态加载能力,只有在类加载期间,甚至是执行期间才能确定目标方法的直接引用. 3.1 解析:在解析阶段,会有一部分符号引用变为直接引用: 包括:静态方法,私有方法,实例构造器,父类方法4中.再加上final修饰的方法 3.2 分派① 静态分派:依靠静态类型来执行方法执行版本的分配动作.典型的应用是方法的重载,会自动加载适合的版本. ② 动态分派:典型额应用是方法的重写.即在运行期才会确定方法执行的版本.]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm之字节码执行引擎</category>
      </categories>
      <tags>
        <tag>字节码执行引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm类加载机制]]></title>
    <url>%2F2019%2F03%2F04%2Fjvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1.概述得知class文件是一段规则有序的二进制流后,类加载流程简述是: 虚拟机将二进制流加载到内存,对数据进行校验,转换解析和初始化,最后形成可以直接被虚拟机使用的java类型. 需要注意的是,java的类型的加载,连接,初始化都是在运行期执行的,从而提供了动态扩展的特性. 由于动态加载的特性,其中解析动作不一定在初始化之前执行. 2.类加载过程2.1 加载① 通过一个类的权限定名称获取这个类的二进制字节流 ② 将这个字节流所代表的静态存储结构转化为方法区的运行时的数据结构 ③ 在内存中生成一个java.lang.class对象,作为方法区这个类的各种数据的访问接口 注: 在类创建的时候,并不包括数组,数组是由java虚拟机直接创建的,不经过类加载器. 但是数组中的元素类型,则会通过类加载器创建. 2.2 验证验证主要是保证字节流中的信息不回危害虚拟机本身,并且符合虚拟机的规范要求.主要有4个方面的验证: ① 文件格式验证: 对开头的二进制魔数进行验证,对主版本号的验证,等等. 目的是保证二进制能够正确解析,存到方法区之内. ② 元数据验证:是否符合java语言规范,比如继承了一个被final修饰的类. ③ 字节码验证: 通过分析数据流和控制流,确定语义是否合法并且符合逻辑. ④ 符号引用验证: 可以看做是对类自身外的信息进行的匹配性校验,比如:是否可以通过权限定名找到相应的类,或者符号引用中的方法字段的可访问性,是否为public或者private等. 2.3 准备此阶段是为类变量分配内存并设置初始值的阶段.这里分配的内存都在方法区进行.并且只会实例化static修饰的变量.类实例变量会在进行类初始化的时候,分配在堆内存中.需要注意的是,private static int a=1;在这句代码中设置的初始值为0,并不是1, ①在类进行初始化后,会为1. ② private static final int a=1,这时也是1. 下面是基本数据类型的零值(准备阶段初始值): 2.4 解析将符号引用变换为直接引用. ① 符号引用: 和内存无关,一组用来描述所引用目标的一组符号. ② 直接引用: 和内存有关,直接引用的数据,在内存中肯定存在.可以是指针,偏移量或者句柄. 主要解析的符号引用为: （1） 类或者接口 （2） 字段 （3） 类方法 （4） 接口方法 （5） 方法类型 （6） 方法句柄 （7） 调用点限定符 2.5 初始化根据java类中的代码进行初始化.也可以说是执行类构造器()方法的执行过程. 类构造器()的具体流程是: （1） 由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生. （2） 和类构造函数不同,不会去调用父类构造器,因为虚拟机会保证父类构造器在子类之前,肯定会执行完.因此第一个执行的类构造器是java.lang.Object. （3） 如果一个类中没有静态语句块和变量赋值操作,则不会生成类构造器. （4） 接口中的如果没有用到父类的变量,则不会生成父类构造器. （5） 虚拟机会保证类构造器在多线程环境下的加锁与同步. 3.类加载器3.1 概述通过一个类的全限定名称来获取类的二进制流的动作 3.2 类与类加载器一个类的唯一性是由同一个类加载器和和这个类本身共同决定的. 一个简单的类加载器: 用这个类加载器和系统加载出来的类,不是同一个类. 3.3 双亲委派模型对于java开发人员来说,有3种系统提供的类加载器: （1） 启动类加载器(bootstrap classLoder):加载/lib下的类,不能被java程序直接引用 （2） 扩展类加载器(extension_classLoder): 由sun.misc.Launcher$ExtClassLoder实现,加载/lib/ext下的类,java程序可以直接使用 （3） 应用程序类加载器(Application classLoder): 由sun.misc.Launcher$app-ClassLoder实现,加载用户类路径下的类.可以直接使用,并且默认类加载器为这个 类加载器层次的关系可以用双亲委派模型来说明,不过层级间不是父子继承关系,而是组合关系.当然这个关系模型是java设计者所推荐的模型. 双亲委派工作流程是: 当一个类加载器接收到加载类的请求时,不会立马去加载这个类,而是将这个请求委派给父类,一直到启动类加载器.当父类无法搜索到这个类时,最终类加载器才会去加载. 3.4 双亲委派模型的破坏1) 在这个模型出现之前,可以继承java.lang.ClassLoder,重写loadClass(),后续建议只有在loadClass()加载失败后,然后再去加载自己的类. 2) 线程上下文类加载器的出现.线程还没创建时,他是父类加载器,如果全局没有设置,则会默认为应用加载器.从而实现了父类加载器请求子类去加载类.所有的SPI操作都是这个原理,比如常见的jdbc,jndi 3) 热部署话等动态的追求,OSGN的java模块化标准.使得每一个模块都有独自的类加载器.双亲委派模型成为一个网状结构,收到类加载请求时,按照以下的标准执行:]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm类加载机制</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>双亲委派模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之类文件结构]]></title>
    <url>%2F2019%2F03%2F04%2F%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[1.1 机器码与字节码①机器码(Native code): 可由CPU直接读取操作的机器指令.处于最底层,不需要编译.速度最快.不可跨平台.依靠硬件存在. ②字节码:是一种中间码，它比机器码更抽象，需要直译器转译后才能成为机器码的中间代码。依靠平台存在. 以前用机器码操作系统，现在是用字节码操作机器码，进一步操作系统,使得语言跨平台成为可能. 1.2.跨平台原理:java语言一如既往的保持着”一次编写,到处运行的特性”,依靠的就是其JVM.JVM不关注语言的来源,只关注的是”CLASS 二进制文件”,只要符合JVM的类的编写规范,就可以经过JVM进行字节码到机器码的转换. 因此, 功能性比较: java或者其他语言&gt;字节码&gt;机器码 速度上:相反 1.3.class文件结构简介:1.3.1.class内容格式Class文件是一组以8位字节为单位的二进制流,各个数据项目以严格的顺序紧凑的排列在CLass文件中,中间没有分隔符.因此文件中的数据全是必要的数据.当遇到需要占用8个字节以上的数据时,则会按照高位在前的方式分割为若干个8位字节进行存储. ①.高位在前,高位字节在地址最低位 例如:32位下,int i=10 低位在前为: 00001010 00000000 00000000 00000000 而在高位优先的内存中： 00000000 00000000 00000000 00001010 字节码本身是无序的,需要有一定的规则去读取数据,高位优先更符合人的操作习惯,但是在X86处理器采用的是低位优先的规则. 1.3.2.class 结构CLass文件中定义了类似于C语言的2种数据类型:无符号数和表. ①.无符号数是最基本的数据类型,用u1,u2,u4,u8分别表示1,2,3,8个字节. ②.表是由无符号数和表构成的复合数据类型.习惯性的以”_info”结尾. 因此Class文件本质上是由众多无符号数组成的一张表. 下面贴上一张结构组成图: 因此,一个class里面会有1个4个字节的magic+1个2个字节的minor_version……..组成.其中具体含义后续详细介绍. 1.3.2.1 magic 魔数在对一个文件进行类型判断时,比如是.png还是.jpg,文件存储标准中都会使用魔数来进行判断.同样,判断是否为一个class文件,也使用了这个标准.对于class文件,开头的前4个字节为魔数,值为:0XCAFEBABE,用来表示这是一个class文件.紧接着魔数后面的4个字节存储着class文件的版本号,5,6位次版本号,7,8是主版本号.高版本的JDK会向下兼容以前版本的class文件,但是会拒绝执行超过其版本的class文件,即使文件格式没有发生变化. 对一个class文件,用16进制编辑器打开,可以看到上面的结果. 第一行的0xCAFEBEBE为文件类型标志,5,6为0x0000次版本号,7,8为0x0032,十进制为50,表示可被1.6以上的jdk进行编译.下面是jdk和class文件版本对应表: 1.3.2.2 constant_pool (常量池)紧接着主版本号之后,便是常量池的入口,可以把常量池比作class文件的资源仓库.这是文件中第一个表数据结构,由于常量的个数不固定,所以在常量池前面会有一个u2类型的数据,constant_pool_count来表示类中定义的常量池的个数.不过常量池会将索引为0的位置留作备用,用来满足指向常量池的索引值需要表示为”不引用任何常量池”的意思.因此常量池的实际个数为constant_pool_count-1. 常量池主要有2中结构:字面量和符号引用. ①.字面量:java语言层面的常量,如文本字符串,final声明的常量等. ②.符号引用:编译方面的概念,主要有类和接口的全限定名,字段的名称和描述符,方法的名称和描述符. 在C/C++,会经历编辑,编译,链接,运行阶段,但是java中没有链接这一阶段,而是采用的是在虚拟机加载类文件的时候动态连接.意思是class文件中不会保存方法字段的占用内存信息,只有在运行期间进行转换才会得到.这部分内容在类加载机制中会详细说明. 常量池中每一个常量都是一张表,开始的第一位是u1类型的标志位,对应关系如下: 每个常量又都会有各自的结构组成, 具体class字节码分析工具,可以用jdk下的bin目录下,javap工具,通过执行: javap -verbose ttclass ​ 可将class转化为字节码,输出. 1.3.2.3 访问标志主要是用于标志一些类和接口层次的信息,占用2个字节 例如:一个普通的public类,access_flags的值为:0x0001+0x0020=0x0021 1.3.2.4 类索引,父类索引,接口索引访问标志后面是这些索引的信息,其中类索引和父类索引是一个u2类型的数据,接口索引是一组u2类型的数据. 顺序为:类索引+父类索引+接口索引大小+接口索引 1.3.2.5 字段表集合字段表是用于描述类或者接口中声明的变量.字段主要有类级变量和实例级变量,不包括方法内部声明的变量. 其中access_flag和类中的访问标志相似.可以设置的值如下: 然后name_index和descriptor_index分别代表了简单名称和描述符; 概念: ① 全限定名:类名中的点变成”/“,例如:org/da/dad/aa.class ② 简单名称: 没有类型和参数修饰的字段或者方法,inf()简称为inf ③ 描述符: 描述字段的数据类型.基本数据类型通常用一个大写字母表示,对象类型用”L+全限定名”来表示. 对于数组类型,一维数组使用[描述,例如int[],用’[I’表示.二维的用’[[‘表示,例如:Integer[][]用[[I表示. 后续的attribute_count和attribute只有在给字段添加默认值的时候,才会显示. 1.3.2.6 方法表集合字段表后面跟着的是方法表,两者很类似, 其中的访问标志选项为: 顺序为:方法数量+访问标志+…(结构体) 其中,方法里面的代码在编译成字节码后,会存放在方法属性表里面,对应的key为Code. 1.3.2.7 属性表集合和其他结构不同,属性表不要求有严格的顺序,长度和内容.只需要和已有的属性名不同即可. java虚拟机定义了21个预定义属性,详情可看书中,暂不一一列举. 对于每一个属性,都会用一个constant_utf8_info属性来表示. 其中简要说下Code属性: code属性是方法里面的代码编译后的字节码: ① attribute_name_index : constant_utf8_info的常量,固定值为”code”,表示属性名称. ② attribute_length: 属性长度,为6个字节. ③ max_stack: 操作栈的深度.java虚拟机会根据这个深度来分配. ④ max_locals: 局部变量表所需要的空间. ⑤ code_length ,code: java源文件编译后的字节码指令. 1.4 字节码指令java虚拟机的指令是由一个字节的,代表某种操作含义的数字(操作码)+(0,n)个代表此操作所需的参数(操作数)组成.但是由于java虚拟机的架构是面向操作数栈而不是面向寄存器的,因此一般都是只有一个操作码组成. 一个字节的操作码长度为:0-255. 因此java虚拟机的执行基础模型为: 1.4.1 字节码与数据类型 在java虚拟机指令集中,大多都会携带其操作所需的数据类型,但是并非所有的数据类型都会有对于的指令.会有一些单独的指令在必要的时候,将不支持的类型转化为支持的.大体上可划分为9个指令. 1.4.2 加载和存储指令主要将数据在栈帧中的局部变量表和操作数栈之间传输,主要包括: ① 将一个局部变量加载到操作栈:iload等; ② 将一个数值从操作栈存储到局部变量表: istore等 ③ 将一个常量加载到操作栈:bipush 1.4.3 运算指令用于对操作数栈上的数值进行某种运算,然后把结果存到栈顶. 注意:java虚拟机没有操作byte,boolean,short,char的指令,最后都会转化为int指令来特殊操作. 1.4.4 类型转化指令 java数据类型及其大小,在进行转化的时候,是默认支持小范围向大范围转化的.而在大范围向小范围转化时,需要进行强制转化. 1.4.5 对象的创建以及访问指令数组和类实例用到了不同的创建指令. 1.4.6 操作数栈管理指令和操作普通的堆栈一样,java虚拟机提供了用于直接操作操作数栈的指令: ① 出栈: pop,pop2 ② 复制栈顶数值,并重新压入栈顶,dup,dup2 ③ 将栈最顶端的2个值互换,swap 1.4.7 控制转移指令有条件或者无条件的修改寄存器的值: 1.4.8 方法调用和返回指令 1.4.9 异常处理指令显示抛出异常的语句,是由athrow指令实现,并且除了显示跑出异常,java虚拟机也会有一些指令进行异常检测. 处理异常(catch语句),没有字节码指令,这部分功能是由异常表来完成 1.4.10 同步指令包括2种同步方式,都是由管程(Monitor)支持: ① 方法级同步: 不通过字节码来操作,是在方法的调用和返回中实现. 流程是:从常量池中取出acc_synchronized得知是否为同步方法,如果是,当前线程则会持有管程,方法执行完后,释放管程.同一个管程只能在一个线程中存在. ② 同步一段指令集序列: 是由java语言的synchronized语句块表示,这个关键字由2个指令支持:monitorenter和monitorexit 例如: 以下代码的字节码为:]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm之类文件结构</category>
      </categories>
      <tags>
        <tag>字节码</tag>
        <tag>字节码指令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java之线程,线程池]]></title>
    <url>%2F2019%2F03%2F03%2Fjava%E4%B9%8B%E7%BA%BF%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[1.线程与进程&nbsp;&nbsp; 进程是系统进行资源分配和调度的独立单位,一个进程下可以包括多个线程.一个进程在执行时,总需要多个子任务去执行,这就需要多线程.最大的利用CPU的空闲时间去执行更多的任务. 2 .创建线程2.1继承Thread类12345678910111213public class StringUtil extends Thread&#123; @Override public void run() &#123; System.out.println(this.getName()); super.run(); &#125; public static void main(String[] args) &#123; for(int i=0;i&lt;100;i++) &#123; new StringUtil().start(); &#125; &#125; &#125; 2.2 实现runnable接口123456789101112public class Aa implements Runnable&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; public static void main(String[] args) &#123; for(int i=0;i&lt;100;i++) &#123; new Thread(new Aa()).start(); &#125; &#125;&#125; 2.3 两种方法对比 看源码1234567891011121314151617publicclass Thread implements Runnable &#123; /* Make sure registerNatives is the first thing &lt;clinit&gt; does. */ private static native void registerNatives(); static &#123; registerNatives(); &#125; private volatile String name; private int priority; /* Whether or not the thread is a daemon thread. */ private boolean daemon = false; /* Fields reserved for exclusive use by the JVM */ private boolean stillborn = false; private long eetop; 在Thread源码中,Thread是Runnable的实现.因此可以得出, a) 我们如果使用继承Thread类,系统已经给我们经过继承,封装好了.可以直接使用. b) 我们如果直接使用实现Runnable接口方式,需要将我们的类放进Thread方法中,去生成一个Thread类,从而具有Thread的所有功能. 由于两种方法基本上是一样的,但是java是单继承的,为了不会影响到我们写的类去继承其他类,所以推荐使用第二种方法. 从demo可知,run()方法是线程中我们需要实现的业务.start()方法是开启一个线程. start()方法源码:1234567891011121314151617181920212223242526272829303132public synchronized void start() &#123; /** * This method is not invoked for the main method thread or &quot;system&quot; * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state &quot;NEW&quot;. */ if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group&apos;s list of threads * and the group&apos;s unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; //开启线程 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125; &#125; &nbsp;&nbsp;可知真正开启一个线程的方法是start0(),并且在创建的时候,用synchronized关键字,进行锁住;同时,可知为了进行线程的管理,将创建的线程加入了线程组. Thread类 线程的方法（Method）、属性（Property） 1）优先级（priority） &amp;nbsp;&amp;nbsp;每个类都有自己的优先级，一般property用1-10的整数表示，默认优先级是5，优先级最高是10；优先级高的线程并不一定比优先级低的线程执行的机会高，只是执行的机率高；默认一个线程的优先级和创建他的线程优先级相同； 2）Thread.sleep()/sleep(long millis) &amp;nbsp;&amp;nbsp;当前线程睡眠/millis的时间（millis指定睡眠时间是其最小的不执行时间，因为sleep(millis)休眠到达后，无法保证会被JVM立即调度）；sleep()是一个静态方法(static method) ，所以他不会停止其他的线程也处于休眠状态；线程sleep()时不会失去拥有的对象锁。 作用：保持对象锁，让出CPU，调用目的是不让当前线程独自霸占该进程所获取的CPU资源，以留一定的时间给其他线程执行的机会； 3）Thread.yield() &amp;nbsp;&amp;nbsp; 让出CPU的使用权，给其他线程执行机会、让同等优先权的线程运行（但并不保证当前线程会被JVM再次调度、使该线程重新进入Running状态），如果没有同等优先权的线程，那么yield()方法将不会起作用。 4）thread.join() 使用该方法的线程会在此之间执行完毕后再往下继续执行。 5）object.wait() 当一个线程执行到wait()方法时，他就进入到一个和该对象相关的等待池(Waiting Pool)中，同时失去了对象的机锁—暂时的，wait后还要返还对象锁。当前线程必须拥有当前对象的锁，如果当前线程不是此锁的拥有者，会抛出IllegalMonitorStateException异常,所以wait()必须在synchronized block中调用。 6）object.notify()/notifyAll() 唤醒在当前对象等待池中等待的第一个线程/所有线程。notify()/notifyAll()也必须拥有相同对象 锁，否则也会抛出IllegalMonitorStateException异常。 7）Synchronizing Block Synchronized Block/方法控制对类成员变量的访问；Java中的每一个对象都有唯一的一个内置的锁，每个Synchronized Block/方法只有持有调用该方法被锁定对象的锁才可以访问，否则所属线程阻塞；机锁具有独占性、一旦被一个Thread持有，其他的Thread就不能再拥有（不能访问其他同步方法），方法一旦执行，就独占该锁，直到从该方法返回时才将锁释放，此后被阻塞的线程方能获得该锁，重新进入可执行状态。 注: 线程组是一个进程下所有的线程管理类,线程以树形的结构存储 线程池是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销 继续查看:源码: 1private native void start0(); 可知最终是调用的原生C/C++方法去开启的一个线程. 3. 线程池: ThreadPoolExecutor&nbsp;&nbsp;ThreadPoolExecutor是jdk1.5之后package java.util.concurrent;官方提供的线程池创建类.主要负责线程的调度,任务的执行,线程池的管理等. 构造方法: 12345678 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 参数 说明 corePoolSize 核心线程池大小 maximumPoolSize 最大线程池大小 keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间；可以allowCoreThreadTimeOut(true)使得核心线程有效时间 unit keepAliveTime时间单位 workQueue 阻塞任务队列 threadFactory 线程工厂 handler 当提交任务数超过maxmumPoolSize+workQueue之和时，任务会交给RejectedExecutionHandler来处理 重点讲解：其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 当workQueue已满，且maximumPoolSize&gt;corePoolSize时，新提交任务会创建新线程执行任务 当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理 当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程 当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 线程池图解: 屏幕剪辑的捕获时间: 2019/2/26 22:23 其中,官方给出了工具类Executors,package java.util.concurrent;,用来快速创建一些线程池方案. 构造一个固定线程数目的线程池，配置的corePoolSize与maximumPoolSize大小相同，同时使用了一个无界LinkedBlockingQueue存放阻塞任务，因此多余的任务将存在再阻塞队列，不会由 RejectedExecutionHandler处理 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 构造一个缓冲功能的线程池，配置corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，keepAliveTime=60s,以及一个无容量的阻塞队列 SynchronousQueue，因此任务提交之后，将会创建新的 线程执行；线程空闲超过60s将会销毁 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 构造一个只支持一个线程的线程池，配置corePoolSize=maximumPoolSize=1，无界阻塞队列 LinkedBlockingQueue；保证任务由一个线程串行执行 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 构造有定时功能的线程池，配置corePoolSize，无界延迟阻塞队列DelayedWorkQueue；有意思的是： maximumPoolSize=Integer.MAX_VALUE，由于DelayedWorkQueue是无界队列，所以这个值是没有意义的 123456789101112public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125;public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); &#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory); &#125; 注: 工具类中提供的创建线程池,所用的队列都是无界队列,因此会存在OOM问题,当然,也可以自定制自己的线程池方案,自定义拒绝策略:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----10 * maximumPoolSize 最大线程池大小----30 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(10)====10容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 10, 30, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(10), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 记录异常 // 报警处理等 System.out.println(&quot;error.............&quot;); &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println(&quot;提交第&quot; + i + &quot;个任务!&quot;); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;running=====&quot;); &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;方法中建立一个核心线程数为30个，缓冲队列有10个的线程池。每个线程任务，执行时会先睡眠3秒，保证提交10任务时，线程数目被占用完，再提交30任务时，阻塞队列被占用完，，这样提交第41个任务是，会交给CustomRejectedExecutionHandler 异常处理类来处理。&nbsp;提交任务的代码如下：123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 注意：41以后提交的任务就不能正常处理了，因为，execute中提交到任务队列是用的offer方法，如上面代码，这个方法是非阻塞的，所以就会交给CustomRejectedExecutionHandler 来处理，所以对于大数据量的任务来说，这种线程池，如果不设置队列长度会OOM，设置队列长度，会有任务得不到处理，接下来我们构建一个阻塞的自定义线程池 定制属于自己的阻塞线程池 :123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package com.tongbanjie.trade.test.commons;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----1 * maximumPoolSize 最大线程池大小----3 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(5)====5容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 1, 3, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(5), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; try &#123; // 核心改造点，由blockingqueue的offer改成put阻塞方法 executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println(&quot;提交第&quot; + i + &quot;个任务!&quot;); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;&gt;&gt;&gt;task is running=====&quot;); TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 解释：当提交任务被拒绝时，进入拒绝机制，我们实现拒绝方法，把任务重新用阻塞提交方法put提交，实现阻塞提交任务功能，防止队列过大，OOM，提交被拒绝方法在下面 public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) // 进入拒绝机制， 我们把runnable任务拿出来，重新用阻塞操作put，来实现提交阻塞功能 reject(command); &#125; 总结： 用ThreadPoolExecutor自定义线程池，看线程是的用途，如果任务量不大，可以用无界队列，如果任务量非常大，要用有界队列，防止OOM 如果任务量很大，还要求每个任务都处理成功，要对提交的任务进行阻塞提交，重写拒绝机制，改为阻塞提交。保证不抛弃一个任务 最大线程数一般设为2N+1最好，N是CPU核数 核心线程数，看应用，如果是任务，一天跑一次，设置为0，合适，因为跑完就停掉了，如果是常用线程池，看任务量，是保留一个核心还是几个核心线程数 如果要获取任务执行结果，用CompletionService，但是注意，获取任务的结果的要重新开一个线程获取，如果在主线程获取，就要等任务都提交后才获取，就会阻塞大量任务结果，队列过大OOM，所以最好异步开个线程获取结果]]></content>
      <categories>
        <category>java基础</category>
        <category>java之线程,线程池</category>
      </categories>
      <tags>
        <tag>线程</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
