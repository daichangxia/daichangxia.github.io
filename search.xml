<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spring-boot-2.0实战]]></title>
    <url>%2F2019%2F11%2F06%2Fspring-boot-2-0%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[spring boot 2.0 实战spring boot 概述spring boot的特点1.快速构建项目 idea插件和官方都提供了快速一键构建一个spring boot的功能. 2.嵌入式web容器 在spring boot 1.0中,默认使用了Tomcat.在spring boot 2.0中,则会根据引入的依赖来决定:spring-boot-starter-web会嵌入Tomcat容器,spring-boot-startrt-webflux会嵌入Netty. 3.易于构建任何应用 spring boot提供了一个强大的starter依赖机制,比如:如果想使用mysql,则引用spring-boot-starter-mysql,在配置文件配置好数据库信息,就可以使用了. 4.自动化配置 在引用一些依赖后,spring boot提供了默认的配置供我们使用.如果需要定制化,则可以在application.yml中修改,就会自动覆盖. 5.开发者工具,热部署 在开发过程中,修改代码总是需要不断的重启项目,spring boot提供了spring-boot-devtools,引入此依赖,在修改代码后,项目会自动重新加载一些必要的类,实现热部署 6.应用监控 spring boot提供了一个依赖:spring-boot-starter-actuator来供我们查看应用的各项指标,如:health(健康检查),dump(活跃线程),env(环境变量),metrics(内存,cpu)等来监控我们的项目.同时可以配合spring-boot-admin-starter-server监控我们的微服务,还有prometheus也可以很简单的加入我们的spring boot 应用程序中. 7.默认提供测试框架 spring boot 默认提供了一个spring-boot-starter-test依赖,可以满足我们日常测试的要求. 8.可执行jar包部署. 由于内嵌了web容器,可以通过maven将spring boot 应用打包成一个jar包,从而快速通过java -jar 启动项目. spring boot的优点1.简化工作 可以简化我们的依赖,配置,部署,监控,测试等. 2.顺应微服务时代 3.背景强大,懂得自然懂. spring boot web实战spring boot webflux1.引入依赖 12345&lt;!--一般不需要写版本号,版本号由partent控制--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; 2.编写请求处理逻辑 1234567891011121314151617package com.example.webflux.handle;import org.springframework.http.MediaType;import org.springframework.stereotype.Component;import org.springframework.web.reactive.function.BodyInserters;import org.springframework.web.reactive.function.server.ServerRequest;import org.springframework.web.reactive.function.server.ServerResponse;import reactor.core.publisher.Mono;@Componentpublic class HelloHandle &#123; public Mono&lt;ServerResponse&gt; hello(ServerRequest request) &#123; String s = request.methodName(); return ServerResponse.ok().contentType(MediaType.APPLICATION_JSON).body(BodyInserters.fromValue(s + " word")); &#125;&#125; 3.编写接收请求的路径 12345678910111213141516171819package com.example.webflux.router;import com.example.webflux.handle.HelloHandle;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.MediaType;import org.springframework.web.reactive.function.server.RequestPredicates;import org.springframework.web.reactive.function.server.RouterFunction;import org.springframework.web.reactive.function.server.RouterFunctions;import org.springframework.web.reactive.function.server.ServerResponse;@Configurationpublic class HelloRouterController &#123; @Bean public RouterFunction&lt;ServerResponse&gt; routerHello(HelloHandle helloHandle) &#123; return RouterFunctions.route(RequestPredicates.GET("/hello") .and(RequestPredicates.accept(MediaType.APPLICATION_JSON)), helloHandle::hello); &#125;&#125; git地址:https://github.com/daicx/spring-boot-2.0-demo/tree/master/webflux spring boot web引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 其余的是经典的写controller层的代码,此处不再编写. 配置文件1.一般使用application.yml格式来定义配置.设置方式为: 12user: name: xiaoming 2.读取方式,需要注意的是,要在已经装配到spring容器中的类中读取. 12@value(&quot;$&#123;user.name&#125;&quot;)private string name; 3.随机数 配置文件中,默认有个随机数函数,用来随机数字,字符串,uuid等: 123456user: intValue: $&#123;random.int&#125; longValue: $&#123;random.long&#125; stringValue: $&#123;random.value&#125; uuidValue: $&#123;random.uuid&#125; int1000value: $&#123;random.int(1000)&#125; 同时可以通过以javabean的形式在接收这些配置,需要在启动类加上:@EnableConfigurationProperties(User.calss) 12345678@configurationProperties(prefix = "user")public class User()&#123; private int intValue; private long longValue; private string stringValue; private string uuidValue; private int int1000value;&#125; 使用的话,在需要使用的类中,引入这个类,就可以读取到配置的属性. 12@Autowiredprivate User user; 4.多环境配置 有时候,我们需要dev,tst,pro的不同的配置,则可以让文件以:application-{name}.yml的格式来命名.然后通过在application.yml中指定:spring.profiles.active={name}来选择使用哪个文件的配置. 页面模板ThymeleafThymeleaf 是spring boot 官方推荐使用的模板框架. 引用依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt; &lt;/dependency&gt; 配置项: 12345678910spring: thymeleaf: #是否开启缓存 cache: false encoding: utf-8 mode: HTML5 #模板文件路径 prefix: classpath:/templates/ #模板文件后缀 suffix: .html demo Freemaker引入依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-freemarker&lt;/artifactId&gt; &lt;/dependency&gt; 配置项: 1234567891011spring: freemarker: template-loader-path: classpath:/templates cache: false charset: UTF-8 check-template-location: true content-type: text/html expose-request-attributes: false expose-session-attributes: false request-context-attribute: request suffix: .ftl demo 国际化: i18n加入i18n配置文件 12345678910111213141516171819202122232425262728@Configurationpublic class i18n &#123; /** * 默认解析器 其中locale表示默认语言 */ @Bean public LocaleResolver localeResolver() &#123; SessionLocaleResolver localeResolver = new SessionLocaleResolver(); localeResolver.setDefaultLocale(Locale.CHINA); return localeResolver; &#125; /** * 默认拦截器 其中lang表示切换语言的参数名 */ @Bean public WebMvcConfigurer localeInterceptor() &#123; return new WebMvcConfigurer() &#123; @Override public void addInterceptors(InterceptorRegistry registry) &#123; LocaleChangeInterceptor localeInterceptor = new LocaleChangeInterceptor(); localeInterceptor.setParamName("lang"); registry.addInterceptor(localeInterceptor); &#125; &#125;; &#125;&#125; demo]]></content>
      <categories>
        <category>spring家族</category>
        <category>spring-boot-2.0实战</category>
      </categories>
      <tags>
        <tag>spring-boot-2.0实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring5开发实战]]></title>
    <url>%2F2019%2F11%2F06%2Fspring5%E5%BC%80%E5%8F%91%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[Spring5 企业开发实战组成Core container核心模块,实现了IOC(控制反转)与DI(依赖注入). Data Access提供了对jdbc,orm,oxm,jms和transaction等模块的支持.使主流的ORM框架,消息中间件,持久化框架等快速的集成到系统. web模块提供了对对象模型-&gt;视图-&gt;控制器(mvc)功能的支持. aop模块提供了面向切面编程的环境,降低各模块间的耦合性. test模块提供了jtest的支持.方便测试. IOC容器原理本质IOC=控制+反转.以前对象的生成是由开发人员控制,而IOC则是将对象的控制转移到了容器,即对象的控制转移.ioc是一种设计理念,它遵守了软件设计原则中的依赖倒置原则,ioc是一种思想,而DI则是具体的实现方式. 注:依赖倒置原则:高层次的模块不应依赖低层次的模块,应当依赖于抽象. 主要组成 beanFactory: 基础的IOC容器,主要是提供了getbean(string name),通过名字获取对象.getType(string name)通过名字获取类型,isSingleton(string name)是否是单例等方法. applicationContext: 爷爷类是beanFactory,提供了一些获取应用名的方法.属于高阶的IOC容器. beanDefinition: javabean对象在容器中的表现形式,包含了类的属性,行为,类型,依赖等功能. 实现过程1.创建beanFactory refreshBeanFactory(),检查上下文中是否存在beanFactory,有则销毁,然后创建. 通过Inputstream()流的方式遍历获取resource资源路径下面的文件,解析xml文件,生成bean对象,然后执行register方法,生成一个以beanName为元素的ArrayList集合和一个concurtenttHashMap以beanname为key,以beanDefnition为value的数据结构. 2.实例化bean (1) 创建bean: 首先遍历第一步生成的arrayList数组,同时以递归的方式,查找到所需要的bean和bean的依赖关系.然后最终执行beanUtil方法的instantiate()方法,实现bean的创建. (2)注入依赖关系: 根据依赖关系,用递归的方式,一层一层的创建并注入依赖的bean,直到与当前bean的依赖链全部注入完成.其中注入最终使用的方法是:找到当前bean的set方法,调用Method的invode方法实现注入. 至此,IOC启动完成. Bean的生命周期1.Spring对Bean进行实例化（相当于程序中的new Xx()） 2.Spring将值和Bean的引用注入进Bean对应的属性中 3.如果Bean实现了BeanNameAware接口，Spring将Bean的ID传递给setBeanName()方法（实现BeanNameAware清主要是为了通过Bean的引用来获得Bean的ID，一般业务中是很少有用到Bean的ID的） 4.如果Bean实现了BeanFactoryAware接口，Spring将调用setBeanDactory(BeanFactory bf)方法并把BeanFactory容器实例作为参数传入。（实现BeanFactoryAware 主要目的是为了获取Spring容器，如Bean通过Spring容器发布事件等） 5.如果Bean实现了ApplicationContextAwaer接口，Spring容器将调用setApplicationContext(ApplicationContext ctx)方法，把y应用上下文作为参数传入.(作用与BeanFactory类似都是为了获取Spring容器，不同的是Spring容器在调用setApplicationContext方法时会把它自己作为setApplicationContext 的参数传入，而Spring容器在调用setBeanDactory前需要程序员自己指定（注入）setBeanDactory里的参数BeanFactory ) 6.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessBeforeInitialization（预初始化）方法（作用是在Bean实例创建成功后对进行增强处理，如对Bean进行修改，增加某个功能） 7.如果Bean实现了InitializingBean接口，Spring将调用它们的afterPropertiesSet方法，作用与在配置文件中对Bean使用init-method声明初始化的作用一样，都是在Bean的全部属性设置成功后执行的初始化方法。 8.如果Bean实现了BeanPostProcess接口，Spring将调用它们的postProcessAfterInitialization（后初始化）方法（作用与6的一样，只不过6是在Bean初始化前执行的，而这个是在Bean初始化后执行的，时机不同 ) 9.经过以上的工作后，Bean将一直驻留在应用上下文中给应用使用，直到应用上下文被销毁 10.如果Bean实现了DispostbleBean接口，Spring将调用它的destory方法，作用与在配置文件中对Bean使用destory-method属性的作用一样，都是在Bean实例销毁前执行的方法。 AOP揭秘简介aop(面向切面编程)是对oop(面向对象编程)的补充和扩展.众所周知,java以其将一系类具有相同属性和行为的事物封装为对象.但是要对一系类对象进行操作(比如监听),则会产生冗余代码.因此,引入aop编程来实现对一系列对象的控制. 原理所使用的的是动态代理.在spring5中,在选择代理方式的时候,会根据代理的对象是否实现了接口,来动态的选择代理的方式.主要有两种方式: jdk的动态代理: 需要代理的对象必须实现接口.由于java是单继承,而jdk的动态代理是生成一个继承了proxy的代理对象.因此就想要具有被代理类的特性,就无法再去继承了,只能以实现接口的方式.使用代理对象,调用invoke()方法,通过反射实现方法的调用. cglib的动态代理: 不需要实现接口.会动态生成一个被代理对象的子类.以callback()的方式来实现方法的调用. 注解组成(AspectJ) @AspectJ:切面. @PointCut:切入点. | 切点指示器 | 功能描述 || ————- | ————————————– || args() | 通过判断目标方法的入参类型 || @args() | 通过判断目标方法的入参是否含有指定注解 || execution() | 满足某一匹配条件 || this() | 满足代理类的所有连接点 || target() | 目标对象为指定类型,比this()范围小 || @target() | 目标对象为指定注解 || within() | 和execution()相似,但是最低精确到类 || @within() | 匹配指定注解的类及其子类 || @annotation() | 匹配带有指定注解的连接点 | @Before:前置通知. @AfterRunning:后置通知. @Around:环绕通知. @AfterThrowing:异常通知. Cilent网络请求客户端基于HTTP的接口的RestTemplate基于webFlux接口的WebClientHTTP2HTTP1.0一次请求响应,就会建立一个连接,用完关闭. HTTP1.1增加了keep-alive参数,是多个请求可以串行执行在一个连接中.前面耗时长的请求会影响到后面的请求. HTTP2多路复用,使多个请求在一个连接上,并且并行执行. 事物特性A(原子性)C(一致性)I(隔离性)D(持久性) 隔离级别 脏读 不可重复读 幻读 读未提交 √ √ √ 读已提交 × √ √ 可重复读 × × √ 串行化 × × × Spring5的事物的支持@TransactionIntercepter,运用的AOP原理. Redis数据类型String,Hash,List,Set,Sortedset 持久化策略一般情况下,redis的数据保存在磁盘中,但是为了让这些数据在机器重启之后还能用,提供了2中持久化策略. RDB在指定的时间内,执行了多少次的操作后,将内存中的数据写到磁盘,生成一个dunp.rdb的文件.机器启动后,读取dump.rdb文件数据到内存. 命令:save 900 1 (在900秒内执行了一次更改,就保存内存数据到磁盘) AOF以日志的形式记录每次写操作,在恢复数据时,将日志里面的数据再执行一遍. 主从复制模式主节点负责接受写入请求,从节点负责查询请求,然后主节点定期同步数据到从节点,此处可见,redis实现的cap原则中的可用性和分区容忍性,没有强一致性. 缺陷: 主节点出现问题后,需要人工指定主节点. 主节点单机写入能力有限. 哨兵模式启动分布式哨兵进程监控各个节点,哨兵有3个定时任务. 每隔10s发送info命令,获取拓部结构图. 每隔2s发送每个哨兵自身的情况和主节点的情况 每个1s像其他节点和哨兵执行ping命令,查看进程情况. 当发现主节点出现问题后,通过选举,将从节点升级为主节点. 问题及处理缓存穿透出现原因:经常查询不存在的数据,导致查询会一直到达数据库. 解决: 缓存空对象,需要更多的存储空间 使用布隆过滤器. 布隆过滤器运用概率性,巧妙的用来判断一定不存在,或者存在. 缓存雪崩出现原因: 缓存的数据在同一时间失效,或者缓存不可用.导致查询直接到数据库. 解决: 保证redis的可用性,建立redis集群. 使用限流降级组件,如Hystrix 优化缓存过期时间 异步重建缓存,即另起线程监控缓存失效期,在其是失效前,对其续约. Zookeeper简介分布式治理服务的框架,一个为分布式提供一致性服务的组件. 配置 tickTime: server端与client端保持心跳时间,每隔tickTIme时间就会有一个心跳.单位:毫秒. initLimit: Leader与Follower初始连接时能容忍的最大心跳数. syncLimit: Leader与Follower保持正常连接所需要的心跳数. dataDir: 数据存放目录. clientPort: 客户端连接断开. dataLogDir: 日志存放目录. 架构组成 Leader: 领导者 Follower: 跟随者 Observer: 观察者 client: 客户端,一般使用apacha的Curator客户端. 选举机制在集群启动时或者leader节点故障是,就会发生选举.每个节点都会向其他节点发送一个投票,内容为:(SID,ZXID),SID:当前机器唯一标志,ZXID:在配置时分配的myid.其他节点在收到信息后,和自己的信息做对比.支持ZXID比自己大的,如果ZXID相同,则支持SID大的. 数据模型采用和文件系统一样的命名空间,每个节点称为一个Znode,有4中类型. 持久节点. 持久顺序节点:节点具有顺序. 临时节点 临时顺序节点 ZK分布式锁创建一个节点,用来表示根节点空间.每个客户端启动都会查询并创建一个临时顺序节点,如果是最小的节点,则获取锁,否则订阅最小的客户端,在最小的客户端释放后,获取锁.为保证原子性,ZK提供的查询最小客户端并订阅,是原子性操作. Kafka简介一款高吞吐量的分布式发布订阅系统.具有解耦,冗余,峰值处理等功能. 组成 broker kafka集群中每台机器称为一个broker topic 每条发送到集群中的消息都会有一个类别,称为topic partition 物理上的分区,每条topic都会被分为一个或者多个partition,持久到磁盘 producer 生产者 consumer 消费者 consumer group 消费者群组,一组消费者去消费消息. 策略 消息处理: 使用内存映射文件,磁盘顺序写入.当内存快满的时候,写入到磁盘. 具有producer像broker推送消息的push模式,由consumer从broker拉取消息的pull模式.push模式可以提交数据处理速度,但会造成消费信息不及时,从而拒绝连接.pull模式则可以根据消费者的消费能力去处理数据,更加可靠. 副本机制,每个leader broker在接收到消息后,会将消息写入到多个Follower 节点中,保证数据可用性. 数据可靠性保障ack通过设置ack来提供数据的可靠性级别 acks 描述 1 默认级别,生产者在leader接收到消息并确认后,发送下一条消息.如果leader宕机,数据丢失 0 生产者不等待leader的返回信息,直接发送下一条消息,此级别数据可靠性最低 -1 生产者需要等到所有ISR(副本同步队列)收到信息并且确认,才发送下一条消息.]]></content>
      <categories>
        <category>spring家族</category>
        <category>spring5实战</category>
      </categories>
      <tags>
        <tag>spring5实战</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql转换成es-rest]]></title>
    <url>%2F2019%2F10%2F24%2Fmysql%E8%BD%AC%E6%8D%A2%E6%88%90es-rest%2F</url>
    <content type="text"><![CDATA[es查询与mysql查询转换es的简介es作为一款搜索引擎,用作快速检索.本文不做es的过多分析,在实际使用中,可能会遇到mysql语句好实现,但是写成es的rest查询就比较困难的情况.因此列举一些常用转换,持续更新中. 所使用框架: bboss-elasticsearch: 一款类似于mybaits,将mysql封装成以xml的方式来进行sql查询.此开源项目是将es的rest语句封装成以xml的方式进行es查询.具有很大的便利性.github地址使用文档 进入正题,案例如下(持续更新中):注:自定义的属性,后面都会带着 _name,可按照实际情况替换. =查询mysql:1select * from table_name where name = &apos;&apos;名字 limit 1; es:123456789GET index_name /_search&#123; &quot;size&quot;: 1, &quot;query&quot;:&#123; &quot;match_phrase&quot;:&#123; &quot;pn&quot;: #[pn] &#125; &#125;&#125; between,order by,limit查询mysql:1select * from table_name where time_name between start_name and end_name order by id_name desc limit 100; es:12345678910111213141516171819202122232425262728293031GET index_name /_search&#123; &quot;size&quot;: 100, &quot;sort&quot;: [ &#123; &quot;time_name&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125; ], &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;: [ &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;range&quot;: &#123; &quot;time_name&quot;: &#123; &quot;from&quot;: &quot;start_name&quot;, &quot;to&quot;: &quot;end_name&quot; &#125; &#125; &#125; ] &#125; &#125; ] &#125; &#125;&#125; min(),max()查询mysql:1select min(time_name),max(time_name) from table_name; es:1234567891011GET index_name/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;grades_stats&quot;: &#123; &quot;stats&quot;: &#123; &quot;field&quot;: &quot;time_name&quot; &#125; &#125; &#125;&#125; es返回值如下,分析结果,提取出值:12345678910111213&quot;aggregations&quot;: &#123; &quot;grades_stats&quot;: &#123; &quot;count&quot;: 10581611, &quot;min&quot;: 1483228800000, &quot;max&quot;: 1571184000000, &quot;avg&quot;: 1527674316115.0793, &quot;sum&quot;: 16165255347820800000, &quot;min_as_string&quot;: &quot;2017-01-01T00:00:00.000Z&quot;, &quot;max_as_string&quot;: &quot;2019-10-16T00:00:00.000Z&quot;, &quot;avg_as_string&quot;: &quot;2018-05-30T09:58:36.115Z&quot;, &quot;sum_as_string&quot;: &quot;292278994-08-17T07:12:55.807Z&quot; &#125;&#125; in,order by,between 查询mysql:1select * from table_name where name in (&apos;名字1&apos;,&apos;名字2&apos;,&apos;名字3&apos;) and time_name between start and end limit 100; es:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455GET index_name/_search&#123; &quot;size&quot;: #[size], &quot;sort&quot;: [&#123; &quot;so_date&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;], &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;:[ #if(1&gt;2) &lt;!--时间范围查询,大于等于操作--&gt; #end &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;range&quot;: &#123; &quot;so_date&quot;: &#123; &quot;from&quot;: #[start_name], &quot;to&quot;: #[end_name] &#125; &#125; &#125; ] &#125; &#125; #if($name &amp;&amp; $name.size() &gt; 0), &#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123; &quot;bool&quot;:&#123; &quot;should&quot;: [ #foreach($nameTmp in $name) #if($velocityCount &gt; 0),#end &#123; &quot;match_phrase&quot;:&#123; &quot;name&quot;:&quot;$nameTmp&quot; &#125; &#125; #end ], &quot;minimum_should_match&quot;: 1 &#125; &#125; ] &#125; &#125; #end ] &#125; &#125; &#125; and ( (a=1 and b=2) or (c=3 and d=4) )操作###对象数组查询:12345class user &#123; private string name; private string desc; private string age;&#125; mysql:1select * from table_name where time_name between start_name and end_name and ( (name=1 and age=2) or (name=3 andage=4) ) ; es:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566GET index_name/_search&#123; &quot;size&quot;: #[size], &quot;sort&quot;: [&#123; &quot;so_date&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125; &#125;], &quot;query&quot;: &#123; &quot;bool&quot;: &#123; &quot;filter&quot;:[ #if(1&gt;2) &lt;!--时间范围查询,大于等于操作--&gt; #end &#123; &quot;bool&quot;: &#123; &quot;must&quot;: [ &#123; &quot;range&quot;: &#123; &quot;so_date&quot;: &#123; &quot;from&quot;: #[start_name], &quot;to&quot;: #[end_name] &#125; &#125; &#125; ] &#125; &#125; #if(1&gt;2) &lt;!--对象数组查询,and ( (a=1 and b=2) or (c=3 and d=4) )操作--&gt; #end #if( $user &amp;&amp; $user.size() &gt; 0 ) ,&#123; &quot;bool&quot;:&#123; &quot;should&quot;:[ #if($user &amp;&amp; $user.size() &gt; 0) #foreach($userTemp in $user) #if($velocityCount &gt; 0),#end &#123; &quot;bool&quot;:&#123; &quot;must&quot;:[ &#123; &quot;match_phrase&quot;:&#123; &quot;name&quot;:&quot;$userTemp.name&quot; &#125; &#125; #if($userTemp.productDetail), &#123; &quot;match_phrase&quot;:&#123; &quot;age&quot;:&quot;$userTemp.age&quot; &#125; &#125; #end ] &#125; &#125; #end #end ] &#125; &#125; #end ] &#125; &#125; &#125; like查询,并对查询结果去重mysql:1select distinct name from table_name where name like &apos;名字%&apos; es:123456789101112131415161718GET index_name/_search&#123; &quot;size&quot;: 0, &quot;query&quot;:&#123; &quot;wildcard&quot;:&#123; &quot;name&quot;:&#123; &quot;value&quot;: #[名字*] &#125; &#125; &#125;, &quot;aggs&quot;: &#123; &quot;distinct&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;name.keyword&quot; &#125; &#125; &#125;&#125; 对聚合结果进行分析,取出所要的值. 去重查询mysql:1select distinct name from table_name; es:1234567891011GET index_name/_search&#123; &quot;size&quot;: 0, &quot;aggs&quot;: &#123; &quot;distinct&quot;: &#123; &quot;terms&quot;: &#123; &quot;field&quot;: &quot;name.keyword&quot; &#125; &#125; &#125;&#125; 去重模糊查询,返回多个字段mysql:1select id_name,name form table_name where name like &quot;名字%&quot; group by name desc ,id_name desc limit 10; es:12345678910111213141516171819202122232425262728293031323334GET index_name/_search&#123; "size": 10, "sort": [&#123; "name.keyword": &#123; "order": "desc" &#125; &#125;], "query":&#123; "wildcard":&#123; "name.keyword":&#123; "value": #[var] &#125; &#125; &#125;, "aggs": &#123; "type":&#123; "terms": &#123; "field": "id_name.keyword", "size": 10 &#125;, "aggs": &#123; "redistinct": &#123; "top_hits": &#123; "sort": [&#123; "id_name.keyword": &#123;"order": "desc"&#125; &#125;], "size": 1 &#125; &#125; &#125; &#125; &#125; &#125;]]></content>
      <categories>
        <category>es</category>
        <category>es rest查询</category>
      </categories>
      <tags>
        <tag>es rest查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO多路复用]]></title>
    <url>%2F2019%2F05%2F15%2FIO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%2F</url>
    <content type="text"><![CDATA[I/O多路复用技术原理1.简介I/O操作指的是应用层去操作内核层.例如:我们写的程序去执行read()操作,读取服务器里面的数据.基于此操作衍生出几种操作模型. 2.堵塞I/O通常IO操作都是阻塞I/O的，也就是说当你调用read时，如果没有数据收到，那么线程或者进程就会被挂起，直到收到数据。阻塞的意思，就是一直等着。阻塞I/O就是等着数据过来，进行读写操作。应用的函数进行调用，但是内核一直没有返回，就一直等着。应用的函数长时间处于等待结果的状态，我们就称为阻塞I/O。每个应用都得等着，每个应用都在等着，浪费啊！很像现实中的情况。大家都不干活，等着数据过来，过来工作一下，没有的话继续等着。 3.非堵塞I/O非阻塞IO很简单，通过fcntl（POSIX）或ioctl（Unix）设为非阻塞模式，这时，当你调用read时，如果有数据收到，就返回数据，如果没有数据收到，就立刻返回一个错误，如EWOULDBLOCK。这样是不会阻塞线程了，但是你还是要不断的轮询来读取或写入。相当于你去查看有没有数据，告诉你没有，过一会再来吧！应用过一会再来问，有没有数据？没有数据，会有一个返回。但是依旧很不好。应用必须得过一会来一下，问问内核有木有数据啊。这和现实很像啊！好多情况都得去某些地方问问好了没有？木有，明天再过来。明天，好了木有？木有，后天再过来。。。。。忙碌的应用。。。。 4.I/O多路复用多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符（FileDescription，简称FD），如果有一个文件描述符（FileDescription）就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）。虾米意思？就是派一个代表，同时监听多个文件描述符是否有数据到来。等着等着，如有有数据，就告诉某某你的数据来啦！赶紧来处理吧。有没有很感动，一个人待着，帮了很多人。医院的黄牛，一个人排队，大家只要把钱给它，它就会把号给需要的人. 5.I/O多路复用实现方式5.1 select 函数1int select (int n, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述副就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以 通过遍历fdset，来找到就绪的描述符。 select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一 个缺点在于单个进程能够监视的文件描述符的数量存在最大限制，在Linux上一般为1024，可以通过修改宏定义甚至重新编译内核的方式提升这一限制，但 是这样也会造成效率的降低。 5.2 poll函数1int poll (struct pollfd *fds, unsigned int nfds, int timeout); 不同与select使用三个位图来表示三个fdset的方式，poll使用一个 pollfd的指针实现。 12345struct pollfd &#123; int fd; /* file descriptor */ short events; /* requested events to watch */ short revents; /* returned events witnessed */&#125;; ​ pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。 注: 从上面看，select和poll都需要在返回后，通过遍历文件描述符来获取已经就绪的socket。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。 5.3 epoll函数epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，没有描述符限制。epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。 epoll操作过程需要三个接口，分别如下： 123int epoll_create(int size)；//创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); 1. int epoll_create(int size);创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议。当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。 2.int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；函数是对指定描述符fd执行op操作。 epfd：是epoll_create()的返回值。 op：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。 fd：是需要监听的fd（文件描述符） epoll_event：是告诉内核需要监听什么事，struct epoll_event结构如下： 12345678910111213struct epoll_event &#123; __uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;;//events可以是以下几个宏的集合：EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；EPOLLOUT：表示对应的文件描述符可以写；EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；EPOLLERR：表示对应的文件描述符发生错误；EPOLLHUP：表示对应的文件描述符被挂断；EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 3. int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout);等待epfd上的io事件，最多返回maxevents个事件。参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。 epool 工作模式: epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式，LT模式与ET模式的区别如下： LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。 ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 LT模式LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 epoll总结在 select/poll中，进程只有在调用一定的方法后，内核才对所有监视的文件描述符进行扫描，而epoll事先通过epoll_ctl()来注册一 个文件描述符，一旦基于某个文件描述符就绪时，内核会采用类似callback的回调机制，迅速激活这个文件描述符，当进程调用epoll_wait() 时便得到通知。(此处去掉了遍历文件描述符，而是通过监听回调的的机制。这正是epoll的魅力所在。) epoll的优点主要是一下几个方面：\1. 监视的描述符数量不受限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左 右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。select的最大缺点就是进程打开的fd是有数量限制的。这对 于连接数量比较大的服务器来说根本不能满足。虽然也可以选择多进程的解决方案( Apache就是这样实现的)，不过虽然linux上面创建进程的代价比较小，但仍旧是不可忽视的，加上进程间数据同步远比不上线程间同步的高效，所以也不是一种完美的方案。 IO的效率不会随着监视fd的数量的增长而下降。epoll不同于select和poll轮询的方式，而是通过每个fd定义的回调函数来实现的。只有就绪的fd才会执行回调函数。 如果没有大量的idle -connection或者dead-connection，epoll的效率并不会比select/poll高很多，但是当遇到大量的idle- connection，就会发现epoll的效率大大高于select/poll。 参考: https://zhuanlan.zhihu.com/p/65013389 https://segmentfault.com/a/1190000003063859]]></content>
      <categories>
        <category>策略</category>
        <category>通信策略</category>
      </categories>
      <tags>
        <tag>io多路复用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之Kafka]]></title>
    <url>%2F2019%2F05%2F15%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BKafka%2F</url>
    <content type="text"><![CDATA[消息队列之Kafka1.简介Kafka是一个基于分布式的消息发布-订阅系统. 2.专用术语① Broker(代理)kafka包含一个或者多个服务器,一个服务器服务器被称为一个Broker. ②Topic(主题)发布到Kafka集群的消息都有一个类别,这个类别成为Topic. ③Partition(分区)物理上的概念,每个Topic包含一个或者多个Partition. ④Replica(副本)每个partition有多个副本,存储在不同的broker上,保证高可用. ⑤Segment(片段)partition是由多个segment组成,每个segment存储着message信息 ⑥Message(消息)基本的通信单位,由一个key,一个value和时间戳组成. ⑦Producer(生产者)消息生产者,向broker发送消息的客户端 ⑧Comsumer(消费者)消息消费者,从broker读取消息的客户端. ⑨ComsumerGroup(消费者群组)每个comsumer属于一个特定的Comsumer Group,一个消息可以发送到多个Comsumer Group,但是一个Comsumer Group中只能有一个Comsumer消费改消息. 3.分布式订阅模型生产者-&gt;brocker-&gt;消费者 4.消费模型采用拉取模型,消费的进度和速度,由消费者决定. 5.高可用模型(多副本)1.对于每一个Topic,我们都可以设置包含有多少个Partition,每个Partition包含Topic的一部分内容. 2.每个broker都会存储一些Partition,因此在kafka集群中,实现了Topic数据的分布式存储. 为了保证,在其中一台broker宕机后,数据不会丢失,采用了常见的分布式处理方式:多副本机制.在Kafka集群中,每个Partition都会有多个副本,包括一个主副本Leader和0或者多个子副本Follower.这些副本分布在不同的broker上,从而保证了数据的完整性. 3.多副本之间的数据同步 副本之间是如何保证同步的呢? 在生产者和消费者操作Kafka的时候,只有主副本Leader提供读写服务.其他Follower副本会不停的对Leader副本发送请求,拉取最新的数据,然后写到磁盘. 4.ISR是什么? ISR全称是“In-Sync Replicas”,意思是保持同步的副本.意思上图中的Follower+Leader. 6.生产者的ACKS参数acks是Producer设置的,选项有3个:0,1,all.含义是生产者的消息确认机制. 6.1 acks=0 当生产者把消息发出去之后,不管是否落到了那个broker的protition中,总是认为是成功了. 缺点:消息发出去,leader还没收到就宕机了,这条消息就丢失了. 6.2 acks=1(默认) 生产者把消息发出去,并且Leader收到并且保存到了磁盘,就认为是成功了. 缺点:Leader在保存后,发生了宕机,数据也会丢失. 6.3 acks=all 生产者发送消息后,Leader和Follower副本(即ISR列表)都将数据保存都了磁盘,就认为是成功了. 注意:需要ISR列表里至少有一个Follower副本. 7消费者 Consumers Kafka提供了两套consumer api，分为high-level api和sample-api。Sample-api 是一个底层的API，它维持了一个和单一broker的连接，并且这个API是完全无状态的，每次请求都需要指定offset值，因此，这套API也是最灵活的。在kafka中，当前读到哪条消息的offset值是由consumer来维护的，因此，consumer可以自己决定如何读取kafka中的数据。比如，consumer可以通过重设offset值来重新消费已消费过的数据。不管有没有被消费，kafka会保存数据一段时间，这个时间周期是可配置的，只有到了过期时间，kafka才会删除这些数据。（这一点与AMQ不一样，AMQ的message一般来说都是持久化到mysql中的，消费完的message会被delete掉）High-level API封装了对集群中一系列broker的访问，可以透明的消费一个topic。它自己维持了已消费消息的状态，即每次消费的都是下一个消息。High-level API还支持以组的形式消费topic，如果consumers有同一个组名，那么kafka就相当于一个队列消息服务，而各个consumer均衡的消费相应partition中的数据。若consumers有不同的组名，那么此时kafka就相当与一个广播服务，会把topic中的所有消息广播到每个consumer。High level api和Low level api是针对consumer而言的，和producer无关。High level api是consumer读的partition的offsite是存在zookeeper上。High level api 会启动另外一个线程去每隔一段时间，offsite自动同步到zookeeper上。换句话说，如果使用了 High level api， 每个message只能被读一次，一旦读了这条message之后，无论我consumer的处理是否ok。High level api的另外一个线程会自动的把offiste+1同步到zookeeper上。如果consumer读取数据出了问题，offsite也会在zookeeper上同步。因此，如果consumer处理失败了，会继续执行下一条。这往往是不对的行为。因此，Best Practice是一旦consumer处理失败，直接让整个conusmer group抛Exception终止，但是最后读的这一条数据是丢失了，因为在zookeeper里面的offsite已经+1了。等再次启动conusmer group的时候，已经从下一条开始读取处理了。Low level api是consumer读的partition的offsite在consumer自己的程序中维护。不会同步到zookeeper上。但是为了kafka manager能够方便的监控，一般也会手动的同步到zookeeper上。这样的好处是一旦读取某个message的consumer失败了，这条message的offsite我们自己维护，我们不会+1。下次再启动的时候，还会从这个offsite开始读。这样可以做到exactly once对于数据的准确性有保证。]]></content>
      <categories>
        <category>java 中间件</category>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列对比]]></title>
    <url>%2F2019%2F05%2F15%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E5%AF%B9%E6%AF%94%2F</url>
    <content type="text"><![CDATA[消息队列对比(持续更新中…) RabbitMq RocketMq Kafka 概念划分 消息代理 消息总线,针对高输入的数据流和重放进行优化 定位 消息队列,消息的可靠性传输 用于存储,读取(重复读取),分析大数据流. 运转机制 主要使用内存 主要使用磁盘 主要是用磁盘 单机吞吐量 6W/S 12W/S 可达18W/S topic优先级 支持 不支持 不支持 消息有效期 消费者使用后从队列中删除 一直存在commit log中,过期删除(默认72小时) 消费者使用后,默认保留一周,可设置为永久. 持久化方式 异步刷盘 异步刷盘,同步刷盘 异步刷盘 运转机制rabbitMq: 分为持久化消息和非持久化消息.并将消息分为索引和内容. 持久化消息:消息过来后存储到磁盘,同时在内存中保留备份,方便快速读取. 非持久化消息: 基本上只保存在内存中,在内存不足的情况下,持久化到磁盘. racketMq: 所有的消息存储到磁盘中一个commit log文件里面,并且有一个逻辑ConsumeQueue,记录了每个队列的在commit log文件的起止地址.所有队列去读取这个文件,运用零拷贝技术读取文件. kafka: 使用零拷贝技术,来实现磁盘文件的快速读取.每个topic的消息被分为多个partation,存储在不同的broker上. 注意点: kafka 由于kafka使用的zookeeper保证数据一致性,消费者默认每隔一段时间提交offset到zk的机制.会有数据丢失和数据重复消费问题: a.机器宕机时,消费者拿到数据还没消费,然后自动提交了offset,那么这条消息丢失. b.机器宕机时,消费者消费了数据,但是还没等提交offset,机器重启后会再次消费数据. 解决办法:关闭默认提交,进行手动提交. 注: 零拷贝: 在linux系统中,存在用户空间和内存空间.每次对文件进行读写时,都会经过这两个空间的传输,就会相当于文件多复制了一份.而零拷贝则是利用虚拟内存技术(即用户空间和内核空间内存中地址直接映射同一个文件),实现文件不用再2个空间之间拷贝就可以读写的方式.netty,kafka,java 的NIO机制,都是使用的此技术. 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司，会去用 RocketMQ，确实很不错（阿里出品），但社区可能有突然黄掉的风险，对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。 本文引自: https://www.cnblogs.com/loytime/p/10449138.html]]></content>
      <categories>
        <category>java 中间件</category>
        <category>消息队列对比</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于WebSocket的研究]]></title>
    <url>%2F2019%2F05%2F15%2F%E5%9F%BA%E4%BA%8EWebSocket%E7%9A%84%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[基于WebSocket的Stomp的研究WebSocket与StompWebSocket是通过单个TCP连接提供全双工通信信道的计算机通信协议.实现的是客户端与服务端的双向通信.STOMP(Simple Text-Orientated Messaging Protocol) 面向消息的简单文本协议. WebSocket处在TCP上非常薄的一层，会将字节流转换为文本/二进制消息，因此，对于实际应用来说，WebSocket的通信形式层级过低，因此，可以在 WebSocket 之上使用 STOMP协议，来为浏览器 和 server间的 通信增加适当的消息语义。 如何理解 STOMP 与 WebSocket 的关系：1) HTTP协议解决了 web 浏览器发起请求以及 web 服务器响应请求的细节，假设 HTTP 协议 并不存在，只能使用 TCP 套接字来 编写 web 应用，你可能认为这是一件疯狂的事情；2) 直接使用 WebSocket（SockJS） 就很类似于 使用 TCP 套接字来编写 web 应用，因为没有高层协议，就需要我们定义应用间所发送消息的语义，还需要确保连接的两端都能遵循这些语义； 3) 同 HTTP 在 TCP 套接字上添加请求-响应模型层一样，STOMP 在 WebSocket 之上提供了一个基于帧的线路格式层，用来定义消息语义； 综上: TCP套接字(底层协议)-&gt;http(高层协议) WebSocket(底层协议)-&gt;Stomp(高层协议) stomp帧格式: 123456789101112131415&gt;&gt;&gt; SENDdestination:/app/chatcontent-length:221&gt;&gt;&gt; SUBSCRIBEid:sub-0destination:/user/22/notifications&lt;&lt;&lt; MESSAGEdestination:/user/22/notificationscontent-type:text/plain;charset=UTF-8subscription:sub-0message-id:kikxsuk1-0content-length:4138 客户端API1.引入js包 2.连接1234567891011121314151617181920212223// 建立连接对象（还未发起连接）var socket=new SockJS("/endpointChatServer");// 获取 STOMP 子协议的客户端对象var stompClient = Stomp.over(socket);// 向服务器发起websocket连接并发送CONNECT帧stompClient.connect( &#123;&#125;,function connectCallback (frame) &#123; // 连接成功时（服务器响应 CONNECTED 帧）的回调方法 document.getElementById("state-info").innerHTML = "连接成功"; console.log('已连接【' + frame + '】'); stompClient.subscribe('/topic/getResponse', function (response) &#123; showResponse(response.body); &#125;); &#125;,function errorCallBack (error) &#123; // 连接失败时（服务器响应 ERROR 帧）的回调方法 document.getElementById("state-info").innerHTML = "连接失败"; console.log('连接失败【' + error + '】'); &#125;); 说明: 1) socket连接对象也可通过WebSocket(不通过SockJS)连接. 1var socket=new WebSocket(&quot;/endpointChatServer&quot;); 2) stompClient.connect()方法签名： 1client.connect(headers, connectCallback, errorCallback); 其中headers表示客户端的认证信息，如： 1234var headers = &#123; login: &apos;mylogin&apos;, passcode: &apos;mypasscode&apos;,&#125;; 若无需认证，直接使用空对象 “{}” 即可； connectCallback 表示连接成功时（服务器响应 CONNECTED 帧）的回调方法；errorCallback 表示连接失败时（服务器响应 ERROR 帧）的回调方法，非必须； 3.断开连接若要从客户端主动断开连接，可调用 disconnect() 方法: 123client.disconnect(function () &#123; alert(&quot;See you next time!&quot;);&#125;; 该方法为异步进行，因此包含了回调参数，操作完成时自动回调； 4.心跳机制若使用STOMP 1.1 版本，默认开启了心跳检测机制，可通过client对象的heartbeat field进行配置（默认值都是10000 ms）： 123client.heartbeat.outgoing = 20000; // client will send heartbeats every 20000msclient.heartbeat.incoming = 0; // client does not want to receive heartbeats from the server// The heart-beating is using window.setInterval() to regularly send heart-beats and/or check server heart-beats 5.发送消息连接成功后，客户端可使用 send() 方法向服务器发送信息： 1client.send(destination url, headers, body); 其中destination url 为服务器 controller中 @MessageMapping 中匹配的URL，字符串，必须参数；headers 为发送信息的header，JavaScript 对象，可选参数；body 为发送信息的 body，字符串，可选参数； 例: 1234//header里面的参数,在服务端用注解:@Headers Map&lt;String,String&gt; headers接收.client.send(&quot;/queue/test&quot;, &#123;priority: 9&#125;, &quot;Hello, STOMP&quot;);//url里面的参数,服务端用注解:@DestinationVariable(&quot;appkey&quot;) String appkey接收.client.send(&quot;/queue/test/&#123;appkey&#125;&quot;, &#123;&#125;, &quot;Hello, STOMP&quot;); 6.消息的订阅 STOMP 客户端要想接收来自服务器推送的消息，必须先订阅相应的URL，即发送一个 SUBSCRIBE 帧，然后才能不断接收来自服务器的推送消息；订阅和接收消息通过 subscribe() 方法实现： 1subscribe(destination url, callback, headers) 其中destination url 为服务器 @SendTo 匹配的 URL，字符串；callback 为每次收到服务器推送的消息时的回调方法，该方法包含参数 message；headers 为附加的headers，JavaScript 对象；什么作用？该方法返回一个包含了id属性的 JavaScript 对象，可作为 unsubscribe() 方法的参数； 例: 123456789var headers = &#123;ack: &apos;client&apos;, &apos;selector&apos;: &quot;location = &apos;Europe&apos;&quot;&#125;;var callback = function(message) &#123; if (message.body) &#123; alert(&quot;got message with body &quot; + message.body) &#125; else &#123; alert(&quot;got empty message&quot;); &#125;&#125;);var subscription = client.subscribe(&quot;/queue/test&quot;, callback, headers); 7.取消订阅123var subscription = client.subscribe(...);subscription.unsubscribe(); 8.JSON的支持STOMP 帧的 body 必须是 string 类型，若希望接收/发送 json 对象，可通过 JSON.stringify() and JSON.parse() 实现；例： 1234567var quote = &#123;symbol: &apos;APPL&apos;, value: 195.46&#125;;client.send(&quot;/topic/stocks&quot;, &#123;&#125;, JSON.stringify(quote));client.subcribe(&quot;/topic/stocks&quot;, function(message) &#123;var quote = JSON.parse(message.body);alert(quote.symbol + &quot; is at &quot; + quote.value);&#125;); 9.事物支持 STOMP 客户端支持在发送消息时用事务进行处理：举例说明： 123456789// start the transaction// 该方法返回一个包含了事务 id、commit()、abort() 的JavaScript 对象var tx = client.begin();// send the message in a transaction// 最关键的在于要在 headers 对象中加入事务 id，若没有添加，则会直接发送消息，不会以事务进行处理client.send(&quot;/queue/test&quot;, &#123;transaction: tx.id&#125;, &quot;message in a transaction&quot;);// commit the transaction to effectively send the messagetx.commit();// tx.abort(); 10.消息接收确认默认情况下，在将消息传递到客户机之前，服务器将自动确认STOMP消息。 客户端可以选择通过订阅目的地来处理消息确认，并将ack头集指定给客户端或单独的客户端。 在这种情况下，客户机必须使用message.ack()方法通知服务器它已经确认了消息。 123456789var subscription = client.subscribe("/queue/test", function(message) &#123; // do something with the message ... // and acknowledge it message.ack(); &#125;, &#123;ack: 'client'&#125;); 服务端1.引入依赖12345//基于spring-boot-2.2.0.M2版本&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-websocket&lt;/artifactId&gt;&lt;/dependency&gt; 2.加入配置文件12345678910111213141516171819@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketStompConfig extends AbstractWebSocketMessageBrokerConfigurer&#123;@Overridepublic void registerStompEndpoints(StompEndpointRegistry registry) &#123; //为 /endpointChatServer 路径启用SockJS功能 registry.addEndpoint("/endpointChatServer").setAllowedOrigins("*").withSockJS();&#125;@Overridepublic void configureMessageBroker(MessageBrokerRegistry registry)&#123; //表明在topic、queue、users这三个域上可以向客户端发消息。 registry.enableSimpleBroker("/topic","/queue","/user"); //客户端向服务端发起请求时，需要以/app为前缀。 registry.setApplicationDestinationPrefixes("/app"); //给指定用户发送一对一的消息前缀是/user。 registry.setUserDestinationPrefix("/user");&#125;&#125; 3.消息传递的三种用例:客户端:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/*STOMP*/var url = &apos;http://localhost:8080/stomp&apos;;var sock = new SockJS(url);var stomp = Stomp.over(sock);var strJson = JSON.stringify(&#123;&apos;message&apos;: &apos;Marco!&apos;&#125;);//默认的和STOMP端点连接/*stomp.connect(&quot;guest&quot;, &quot;guest&quot;, function (franme) &#123;&#125;);*/var headers=&#123; username:&apos;admin&apos;, password:&apos;admin&apos;&#125;;stomp.connect(headers, function (frame) &#123; //发送消息 //第二个参数是一个头信息的Map，它会包含在STOMP的帧中 //事务支持 var tx = stomp.begin(); stomp.send(&quot;/app/marco&quot;, &#123;transaction: tx.id&#125;, strJson); tx.commit(); //订阅服务端消息 subscribe(destination url, callback, headers) stomp.subscribe(&quot;/topic/marco&quot;, function (message) &#123; var content = message.body; var obj = JSON.parse(content); console.log(&quot;订阅的服务端消息：&quot; + obj.message); &#125;, &#123;&#125;); stomp.subscribe(&quot;/app/getShout&quot;, function (message) &#123; var content = message.body; var obj = JSON.parse(content); console.log(&quot;订阅的服务端直接返回的消息：&quot; + obj.message); &#125;, &#123;&#125;); /*以下是针对特定用户的订阅*/ var adminJSON = JSON.stringify(&#123;&apos;message&apos;: &apos;ADMIN&apos;&#125;); /*第一种*/ stomp.send(&quot;/app/singleShout&quot;, &#123;&#125;, adminJSON); stomp.subscribe(&quot;/user/queue/shouts&quot;,function (message) &#123; var content = message.body; var obj = JSON.parse(content); console.log(&quot;admin用户特定的消息1：&quot; + obj.message); &#125;); /*第二种*/ stomp.send(&quot;/app/shout&quot;, &#123;&#125;, adminJSON); stomp.subscribe(&quot;/user/queue/notifications&quot;,function (message) &#123; var content = message.body; var obj = JSON.parse(content); console.log(&quot;admin用户特定的消息2：&quot; + obj.message); &#125;); //若使用STOMP 1.1 版本，默认开启了心跳检测机制（默认值都是10000ms） stomp.heartbeat.outgoing = 20000; stomp.heartbeat.incoming = 0; //客户端不从服务端接收心跳包&#125;); 3.1广播12345678910111213141516171819@MessageMapping(&quot;/marco&quot;)@SendTo(&quot;/topic/marco&quot;) public Shout stompHandle(Shout shout)&#123; LOGGER.info(&quot;接收到消息：&quot; + shout.getMessage()); Shout s = new Shout(); s.setMessage(&quot;Polo!&quot;); return s; &#125; //方式2 @Autowired private SimpMessagingTemplate messagingTemplate; /** * 广播消息，不指定用户，所有订阅此的用户都能收到消息 * @param shout */ @MessageMapping(&quot;/broadcastShout&quot;) public void broadcast(String shout) &#123; messagingTemplate.convertAndSend(&quot;/topic/shouts&quot;, shout); &#125; 3.2 点对点聊天12345678@Autowired private SimpMessagingTemplate messagingTemplate;@MessageMapping(&quot;/chat&quot;) public void handleChat( String msg) &#123; messagingTemplate .convertAndSendToUser(&quot;hjx&quot;, &quot;/queue/notifications&quot;, msg+ &quot;-send:&quot; + msg); &#125; 3.3 客户端与服务端的通信前端 1234567891011var sock = new SockJS(&quot;http://127.0.0.1:8080/endpointChatServer&quot;); var stomp = Stomp.over(sock); var headers = &#123; platform : &apos;mylogin&apos;, name : &apos;mypasscode&apos;, &#125;; stomp.connect(&#123;&#125;, function(frame) &#123; //此处订阅了点对点的通信,注意22为返回用户id stomp.subscribe(&quot;/user/22/notifications&quot;, handleNotification) &#125;)stomp.send(&quot;/app/appkey/chat-test/22&quot;, headers,reader.result) 后端 config: 123456789101112131415161718192021222324252627import org.springframework.context.annotation.Configuration;import org.springframework.messaging.simp.config.MessageBrokerRegistry;import org.springframework.web.socket.config.annotation.EnableWebSocketMessageBroker;import org.springframework.web.socket.config.annotation.StompEndpointRegistry;import org.springframework.web.socket.config.annotation.WebSocketMessageBrokerConfigurer;@Configuration@EnableWebSocketMessageBrokerpublic class WebSocketConfig implements WebSocketMessageBrokerConfigurer &#123; @Override public void configureMessageBroker(MessageBrokerRegistry registry) &#123; //表明在topic、queue、users这三个域上可以向客户端发消息。 registry.enableSimpleBroker(&quot;/topic&quot;,&quot;/user&quot;); //客户端向服务端发起请求时，需要以/app为前缀。 registry.setApplicationDestinationPrefixes(&quot;/app&quot;); //给指定用户发送一对一的消息前缀是/user。 registry.setUserDestinationPrefix(&quot;/user&quot;); &#125; @Override public void registerStompEndpoints(StompEndpointRegistry registry) &#123; registry.addEndpoint(&quot;/endpointChatServer&quot;).setAllowedOrigins(&quot;*&quot;).withSockJS(); &#125; &#125; 使用: 1234567891011@Autowired // 通过SimpMessagingTemplate模板向浏览器发送消息。如果是广播模式，可以直接使用注解@SendToprivate SimpMessagingTemplate simpMessagingTemplate;@MessageMapping(&quot;/&#123;appkey&#125;/chat-test/&#123;to&#125;&quot;) public void handleChatTest(String message,@DestinationVariable(&quot;to&quot;) String to,@Headers Map&lt;String, String&gt; header) &#123; System.out.println(&quot;开始chat&quot;); //此处的to对应上面的用户id,22 simpMessagingTemplate.convertAndSendToUser( to,&quot;/notifications&quot;,header+message); System.out.println(&quot;结束chat&quot;); &#125;]]></content>
      <categories>
        <category>通信机制</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx十万并发配置]]></title>
    <url>%2F2019%2F04%2F19%2FNginx%E5%8D%81%E4%B8%87%E5%B9%B6%E5%8F%91%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Nginx 数十万并发设置 1.系统参数1234567891011121314151617[root@node101 ~]# ulimit -a core file size (blocks, -c) 0 #core文件的最大值为100 blocks。data seg size (kbytes, -d) unlimited #进程的数据段可以任意大。scheduling priority (-e) 0 #指定调度优先级file size (blocks, -f) unlimited #文件可以任意大。pending signals (-i) 31152 #最多有31152个待处理的信号。max locked memory (kbytes, -l) 64 #一个任务锁住的物理内存的最大值为64KB。max memory size (kbytes, -m) unlimited #一个任务的常驻物理内存的最大值。open files (-n) 1024 #一个任务最多可以同时打开1024的文件。pipe size (512 bytes, -p) 8 #管道的最大空间为4096字节。POSIX message queues (bytes, -q) 819200 #POSIX的消息队列的最大值为819200字节。real-time priority (-r) 0 #指定实时优先级stack size (kbytes, -s) 8192 #进程的栈的最大值为8192字节。cpu time (seconds, -t) unlimited #进程使用的CPU时间。max user processes (-u) 31152 #当前用户同时打开的进程（包括线程）的最大个数为31152。virtual memory (kbytes, -v) unlimited #没有限制进程的最大地址空间。file locks (-x) unlimited #所能锁住的文件的最大个数没有限制。 2.nginx参数调优worker进程数是否合理1worker_processes auto; nginx worker进程数量，建议和cpu核数相当. 分析: worker_processes是worker进程的数量，默认值为auto，这个优化值受很多因素的影响，如果不确定的话，将其设置为CPU内核数是一个不错的选择 worker连接数是否合理1worker_connections 1024; 单个worker进程可服务的客户端数量（根据并发要求进行更改） 分析:worker_connections 设置了一个worker进程可以同时打开的链接数，有高并发需求时，按照需求进行设定。链接最大数目= worker_processes * worker_connections worker可打开最大文件数是否合理1worker_rlimit_nofileulimit -n Nginx 最大可用文件描述符数量linux可同时打开最大文件数 分析:worker_rlimit_nofile为Nginx单个worker进程最大可用文件描述符数量，和链接数相同；最大数目= worker_processes * worker_rlimit_nofile。 同时需要配置操作系统的 “ulimit -n XXXX”，或者在 /etc/security/limits.conf 中配置。 来达到对应配置。 配置数量按照需求情况设定，不建议配置较高的值。 multi_accept1multi_accept on; 是否尽可能的接受请求（建议打开） 分析: multi_accept 的作用是告诉 nginx 在收到新链接的请求通知时，尽可能接受链接。当然，得让他开着。 读写方式是否合理1sendfile on; 直接从磁盘上读取数据到操作系统缓冲（建议打开） 分析: ​ 在 sendfile 出现之前，为了传输这样的数据，需要在用户空间上分配一块数据缓存，使用 read() 从源文件读取数据到缓存，然后使用 write() 将缓存写入到网络。 sendfile() 直接从磁盘上读取数据到操作系统缓冲。由于这个操作是在内核中完成的，sendfile() 比 read() 和 write() 联合使用要更加有效率。 tcp_nopush1tcp_nopush on; 在一个包中发送全部头文件（建议打开,默认为打开状态） 分析: 配置 nginx 在一个包中发送全部的头文件，而不是一个一个发送。这个选项使服务器在 sendfile 时可以提前准备 HTTP 首部，能够达到优化吞吐的效果。 tcp_nodelay1tcp_nodelay on; 配置 nginx 不缓存数据，快速发送小数据 分析: 不要缓存 data-sends （关闭 Nagle 算法），这个能够提高高频发送小数据报文的实时性。系统存在高频发送小数据报文的时候，打开它。 客户端在keep-alive的请求数量是否合理1keepalive_requests 100000; 建议配置较大的值 分析: 设置通过”一个存活长连接”送达的最大请求数（默认是100，建议根据客户端在”keepalive”存活时间内的总请求数来设置）当送达的请求数超过该值后，该连接就会被关闭。（通过设置为5，验证确实是这样）建议设置为一个较大的值 客户端通信超时时间是否合理1keepalive_timeout 65; 超时时间. 分析: ​ 配置连接 keep-alive 超时时间，服务器将在超时之后关闭相应的连接。 指定了与客户端的 keep-alive 链接的超时时间。服务器会在这个时间后关闭链接。 keep-alive设置过小客户端和服务器会频繁建立连接；设置过大由于连接需要等待keep-alive才会关闭，所以会造成不必要的资源浪费。 后端服务器超时时间是否合理12345proxy_connect_timeout //默认60sproxy_read_timeout //默认60sproxy_send_timeout //默认60s 默认60s 分析: proxy_connect_timeout :后端服务器连接的超时时间_发起握手等候响应超时时间 proxy_read_timeout:连接成功后等候后端服务器响应时间其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_send_timeout :后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据 reset_timedout_connection配置是否合理1reset_timedout_connection on; 服务器在客户端停止发送应答之后关闭连接. 分析: ​ 允许server在client停止响应以后关闭连接,释放分配给该连接的内存。当有大并发需求时，建议打开。 request body读超时时间是否合理1client_body_timeout 10; 默认60s. 分析; 该指令设置请求体（request body）的读超时时间。仅当在一次readstep中，没有得到请求体，就会设为超时。超时后，nginx返回HTTP状态码408(“Request timed out”) types_hash_max_size1types_hash_max_size 2048; types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 分析; ​ ypes_hash_max_size影响散列表的冲突率。types_hash_max_size越大，就会消耗更多的内存，但散列key的冲突率会降低，检索速度就更快。types_hash_max_size越小，消耗的内存就越小，但散列key的冲突率可能上升。 日志记录是否合理1access_log /var/log/nginx/access.log main; #默认打开 access_log和error_logaccess_log建议关闭，降低磁盘IO提高速度error_log 压缩选用是否合理1234567# nginx默认不进行压缩处理 gzip on; gzip_disable &quot;msie6&quot;; gzip_proxied any; gzip_comp_level 9; gzip_types text/plain text/css application/json application/x-javascript text/xml application/xml application/xml+rss text/javascript;设置数据压缩设置禁止压缩是否压缩基于请求、响应的压缩压缩等级压缩类型 gzip ：设置nginx gzip压缩发送的数据，建议打开 gzip_disable：为指定的客户端禁用gzip功能，(IE5.5和IE6 SP1使用msie6参数来禁止gzip压缩 )指定哪些不需要gzip压缩的浏览器(将和User-Agents进行匹配),依赖于PCRE库 gzip_proxied：Nginx作为反向代理的时候启用，根据某些请求和应答来决定是否在对代理请求的应答启用gzip压缩，是否压缩取决于请求头中的“Via”字段，指令中可以同时指定多个不同的参数，意义如下（ 无特殊需求建议设置为any）： off(关闭所有代理结果的数据的压缩) expired - 启用压缩，如果header头中包含 “Expires” 头信息 no-cache - 启用压缩，如果header头中包含 “Cache-Control:no-cache” 头信息 no-store - 启用压缩，如果header头中包含 “Cache-Control:no-store” 头信息 private - 启用压缩，如果header头中包含 “Cache-Control:private” 头信息 no_last_modified - 启用压缩,如果header头中不包含 “Last-Modified” 头信息 no_etag - 启用压缩 ,如果header头中不包含 “ETag” 头信息 auth - 启用压缩 , 如果header头中包含 “Authorization” 头信息 any - 无条件启用压缩 gzip_comp_level：数据压缩的等级。等级可以是 1-9 的任意一个值，9 表示最慢但是最高比例的压缩 gzip_types：设置进行 gzip 的类型；对于多数以文本为主的站点来说，文本自身内容占流量的绝大部分。虽然单个文本体积并不算大，但是如果数量众多的话，流量还是相当可观。启用GZIP以后，可以大幅度减少所需的流量. linux系统是否启用epoll1use epoll; Linux 关键配置，允许单个线程处理多个客户端请求。 分析: ​ Linux 关键配置，允许单个线程处理多个客户端请求。 缓存设置是否合理1234567open_file_cache max=200000 inactive=20s;//缓存最大数目及超时时间检测open_file_cache_valid 30s; //缓存源文件是否超时的间隔时间open_file_cache_min_uses 2;//缓存文件最小访问次数open_file_cache_errors on;//缓存文件错误信息 3.服务器内核参数调优net.ipv4.tcp_max_tw_buckets = 6000 timewait 的数量，默认是180000。 net.ipv4.ip_local_port_range = 1024 65000 允许系统打开的端口范围。 net.ipv4.tcp_tw_recycle = 1 启用timewait 快速回收。 net.ipv4.tcp_tw_reuse = 1 开启重用。允许将TIME-WAIT sockets 重新用于新的TCP 连接。 net.ipv4.tcp_syncookies = 1 开启SYN Cookies，当出现SYN 等待队列溢出时，启用cookies 来处理。 net.core.somaxconn = 262144 web 应用中listen 函数的backlog 默认会给我们内核参数的net.core.somaxconn 限制到128，而nginx 定义的NGX_LISTEN_BACKLOG 默认为511，所以有必要调整这个值。 net.core.netdev_max_backlog = 262144 每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 net.ipv4.tcp_max_orphans = 262144 系统中最多有多少个TCP 套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，孤儿连接将即刻被复位并打印出警告信息。这个限制仅仅是为了防止简单的DoS 攻击，不能过分依靠它或者人为地减小这个值，更应该增加这个值(如果增加了内存之后)。 net.ipv4.tcp_max_syn_backlog = 262144 记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M 内存的系统而言，缺省值是1024，小内存的系统则是128。 net.ipv4.tcp_timestamps = 0 时间戳可以避免序列号的卷绕。一个1Gbps 的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉。 net.ipv4.tcp_synack_retries = 1 为了打开对端的连接，内核需要发送一个SYN 并附带一个回应前面一个SYN 的ACK。也就是所谓三次握手中的第二次握手。这个设置决定了内核放弃连接之前发送SYN+ACK 包的数量。 net.ipv4.tcp_syn_retries = 1 在内核放弃建立连接之前发送SYN 包的数量。 net.ipv4.tcp_fin_timeout = 1 如 果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2 状态的时间。对端可以出错并永远不关闭连接，甚至意外当机。缺省值是60 秒。2.2 内核的通常值是180 秒，3你可以按这个设置，但要记住的是，即使你的机器是一个轻载的WEB 服务器，也有因为大量的死套接字而内存溢出的风险，FIN- WAIT-2 的危险性比FIN-WAIT-1 要小，因为它最多只能吃掉1.5K 内存，但是它们的生存期长些。 net.ipv4.tcp_keepalive_time = 30 当keepalive 起用的时候，TCP 发送keepalive 消息的频度。缺省是2 小时。 4.nginx.conf配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869user root;# cpu数量，建议使用默认worker_processes auto;pid /run/nginx.pid;# 配置nginx worker进程最大打开文件数 worker_rlimit_nofile 65535;events &#123; # 单个进程允许的客户端最大连接数 worker_connections 20480; # multi_accept on;&#125;http &#123; ## # Basic Settings ## sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; gzip_disable "msie6"; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*;&#125; 5.内核配置文件1234567891011121314151617181920212223242526272829303132net.ipv4.ip_forward = 0net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.default.accept_source_route = 0kernel.sysrq = 0kernel.core_uses_pid = 1net.ipv4.tcp_syncookies = 1kernel.msgmnb = 65536kernel.msgmax = 65536kernel.shmmax = 68719476736kernel.shmall = 4294967296net.ipv4.tcp_max_tw_buckets = 6000net.ipv4.tcp_sack = 1net.ipv4.tcp_window_scaling = 1net.ipv4.tcp_rmem = 4096 87380 4194304net.ipv4.tcp_wmem = 4096 16384 4194304net.core.wmem_default = 8388608net.core.rmem_default = 8388608net.core.rmem_max = 16777216net.core.wmem_max = 16777216net.core.netdev_max_backlog = 262144net.core.somaxconn = 262144net.ipv4.tcp_max_orphans = 3276800net.ipv4.tcp_max_syn_backlog = 262144net.ipv4.tcp_timestamps = 0net.ipv4.tcp_synack_retries = 1net.ipv4.tcp_syn_retries = 1net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_mem = 94500000 915000000 927000000net.ipv4.tcp_fin_timeout = 1net.ipv4.tcp_keepalive_time = 30net.ipv4.ip_local_port_range = 1024 65000 vi /etc/sysctl.conf CentOS5.5中可以将所有内容清空直接替换. 使配置立即生效可使用如下命令：/sbin/sysctl -p 6.系统连接数linux 默认值 open files 和 max user processes 为 1024 #ulimit -n 1024 #ulimit Cu 1024 问题描述： 说明 server 只允许同时打开 1024 个文件，处理 1024 个用户进程 使用ulimit -a 可以查看当前系统的所有限制值，使用ulimit -n 可以查看当前的最大打开文件数。 新装的linux 默认只有1024 ，当作负载较大的服务器时，很容易遇到error: too many open files 。因此，需要将其改大。 解决方法： 使用 ulimit Cn 65535 可即时修改，但重启后就无效了。（注ulimit -SHn 65535 等效 ulimit -n 65535 ，-S 指soft ，-H 指hard) 有如下三种修改方式： \1. 在/etc/rc.local 中增加一行 ulimit -SHn 65535 2. 在/etc/profile 中增加一行 ulimit -SHn 65535 3. 在/etc/security/limits.conf 最后增加： 1234* soft nofile 65535* hard nofile 65535* soft nproc 65535* hard nproc 65535 具体使用哪种，在 CentOS 中使用第1 种方式无效果，使用第3 种方式有效果，而在Debian 中使用第2 种有效果 # ulimit -n 65535 # ulimit -u 65535 备注：ulimit 命令本身就有分软硬设置，加-H 就是硬，加-S 就是软默认显示的是软限制 soft 限制指的是当前系统生效的设置值。 hard 限制值可以被普通用户降低。但是不能增加。 soft 限制不能设置的比 hard 限制更高。 只有 root 用户才能够增加 hard 限制值。]]></content>
      <categories>
        <category>Nginx</category>
        <category>Nginx十万并发</category>
      </categories>
      <tags>
        <tag>Nginx并发配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置介绍]]></title>
    <url>%2F2019%2F04%2F19%2FNginx%E9%85%8D%E7%BD%AE%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[Nginx配置信息详解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327#nginx进程,一般设置为和cpu核数一样,使用auto将自动配置worker_processes 4; #错误日志存放目录 error_log /data/logs/error.log crit; #运行用户，默认即是nginx，可不设置user nginx #进程pid存放位置pid /application/nginx/nginx.pid; #Specifies the value for maximum file descriptors that can be opened by this process. #最大文件打开数（连接），可设置为系统优化后的ulimit -HSn的结果worker_rlimit_nofile 51200;#cpu亲和力配置，让不同的进程使用不同的cpuworker_cpu_affinity 0001 0010 0100 1000 0001 00100100 1000;#工作模式及连接数上限events &#123; use epoll; #epoll是多路复用IO(I/O Multiplexing)中的一种方式,但是仅用于linux2.6以上内核,可以大大提高nginx的性能 worker_connections 1024; #;单个后台worker process进程的最大并发链接数&#125;http &#123;include mime.types; #文件扩展名与类型映射表default_type application/octet-stream; #默认文件类型#limit模块，可防范一定量的DDOS攻击#用来存储session会话的状态，如下是为session分配一个名为one的10M的内存存储区，限制了每秒只接受一个ip的一次请求 1r/s limit_req_zone $binary_remote_addr zone=one:10m rate=1r/s; limit_conn_zone $binary_remote_addr zone=addr:10m; include mime.types; default_type application/octet-stream;#第三方模块lua防火墙 lua_need_request_body on; #lua_shared_dict limit 50m; lua_package_path &quot;/application/nginx/conf/waf/?.lua&quot;; init_by_lua_file &quot;/application/nginx/conf/waf/init.lua&quot;; access_by_lua_file &quot;/application/nginx/conf/waf/access.lua&quot;; #设定请求缓存 server_names_hash_bucket_size 128; client_header_buffer_size 512k; large_client_header_buffers 4 512k; client_max_body_size 100m; #隐藏响应header和错误通知中的版本号 server_tokens off; #开启高效传输模式 sendfile on; #激活tcp_nopush参数可以允许把httpresponse header和文件的开始放在一个文件里发布,积极的作用是减少网络报文段的数量,tcp_nopush = on 会设置调用tcp_cork方法，这个也是默认的，结果就是数据包不会马上传送出去，等到数据包最大时，一次性的传输出去，这样有助于解决网络堵塞。对于nginx配置文件中的tcp_nopush，默认就是tcp_nopush,不需要特别指定，这个选项对于www，ftp等大文件很有帮助. tcp_nopush on; #激活tcp_nodelay，内核会等待将更多的字节组成一个数据包，从而提高I/O性能.TCP_NODELAY和TCP_CORK基本上控制了包的“Nagle化”，Nagle化在这里的含义是采用Nagle算法把较小的包组装为更大的帧。Nagle化后来成了一种标准并且立即在因特网上得以实现。它现在已经成为缺省配置了. # 现在让我们假设某个应用程序发出了一个请求，希望发送小块数据。我们可以选择立即发送数据或者等待产生更多的数据然后再一次发送两种策略。如果我们马上发送数据，那么交互性的以及客户/服务器型的应用程序将极大地受益。如果请求立即发出那么响应时间也会快一些。以上操作可以通过设置套接字的TCP_NODELAY = on 选项来完成，这样就禁用了Nagle 算法。 另外一种情况则需要我们等到数据量达到最大时才通过网络一次发送全部数据，这种数据传输方式有益于大量数据的通信性能，典型的应用就是文件服务器。应用 Nagle算法在这种情况下就会产生问题。但是，如果你正在发送大量数据，你可以设置TCP_CORK选项禁用Nagle化，其方式正好同 TCP_NODELAY相反（TCP_CORK和 TCP_NODELAY是互相排斥的）。 tcp_nodelay on; #FastCGI相关参数：为了改善网站性能：减少资源占用，提高访问速度fastcgi_connect_timeout 300;fastcgi_send_timeout 300;fastcgi_read_timeout 300;fastcgi_buffer_size 64k;fastcgi_buffers 4 64k;fastcgi_busy_buffers_size 128k;fastcgi_temp_file_write_size 128k;#连接超时时间，单位是秒 keepalive_timeout 60; #开启gzip压缩功能 gzip on； #设置允许压缩的页面最小字节数，页面字节数从header头的Content-Length中获取。默认值是0，表示不管页面多大都进行压缩。建议设置成大于1K。如果小于1K可能会越压越大。 gzip_min_length 1k;#压缩缓冲区大小。表示申请4个单位为16K的内存作为压缩结果流缓存，默认值是申请与原始数据大小相同的内存空间来存储gzip压缩结果。 gzip_buffers 4 16k;#压缩版本（默认1.1，前端为squid2.5时使用1.0）用于设置识别HTTP协议版本，默认是1.1，目前大部分浏览器已经支持GZIP解压，使用默认即可。 gzip_http_version 1.0;#压缩比率。用来指定GZIP压缩比，1压缩比最小，处理速度最快；9压缩比最大，传输速度快，但处理最慢，也比较消耗cpu资源。 gzip_comp_level 9;#用来指定压缩的类型，“text/html”类型总是会被压缩 gzip_types text/plain application/x-javascript text/css application/xml; #vary header支持。该选项可以让前端的缓存服务器缓存经过GZIP压缩的页面，例如用Squid缓存经过Nginx压缩的数据。gzip_vary off;#开启ssi支持，默认是off ssi on; ssi_silent_errors on;#设置日志模式 log_format access &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $http_x_forwarded_for&apos;;#反向代理负载均衡设定部分#upstream表示负载服务器池，定义名字为backend_server的服务器池upstream backend_server &#123; server 10.254.244.20:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.242.40:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.245.19:81 weight=1 max_fails=2 fail_timeout=30s; server 10.254.243.39:81 weight=1 max_fails=2 fail_timeout=30s; #设置由 fail_timeout 定义的时间段内连接该主机的失败次数，以此来断定 fail_timeout 定义的时间段内该主机是否可用。默认情况下这个数值设置为 1。零值的话禁用这个数量的尝试。设置在指定时间内连接到主机的失败次数，超过该次数该主机被认为不可用。#这里是在30s内尝试2次失败即认为主机不可用！ &#125;####################基于域名的虚拟主机 server &#123;#监听端口 listen 80; server_name www.abc.com abc.com; index index.html index.htm index.php; #首页排序 root /data0/abc; #站点根目录，即网站程序存放目录 error_page 500 502 404 /templates/kumi/phpcms/404.html; #错误页面#伪静态 将www.abc.com/list....html的文件转发到index.php。。。#rewrite ^/list-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\.html$ /index.php?m=content&amp;c=index&amp;a=lists&amp;catid=$1&amp;types=$2&amp;country=$3&amp;language=$4&amp;age=$5&amp;startDate=$6&amp;typeLetter=$7&amp;type=$8&amp;page=$9 last;#location 标签，根目录下的.svn目录禁止访问 location ~ /.svn/ &#123; deny all; &#125; location ~ \.php$ &#123; #符合php扩展名的请求调度到fcgi server fastcgi_pass 127.0.0.1:9000; #抛给本机的9000端口 fastcgi_index index.php; #设定动态首页 include fcgi.conf; &#125; allow 219.237.222.30 ; #允许访问的ip allow 219.237.222.31 ; allow 219.237.222.32 ; allow 219.237.222.33 ; allow 219.237.222.34 ; allow 219.237.222.35 ; allow 219.237.222.61 ; allow 219.237.222.28 ; deny all; #禁止其他ip访问 &#125; location ~ ^/admin.php &#123; location ~ \.php$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fcgi.conf; &#125; allow 219.237.222.30 ; allow 219.237.222.31 ; allow 219.237.222.32 ; allow 219.237.222.33 ; allow 219.237.222.34 ; allow 219.237.222.35 ; allow 219.237.222.61; allow 219.237.222.28; deny all; &#125;#将符合js,css文件的等设定expries缓存参数，要求浏览器缓存。location~ .*\.(js|css)?$ &#123; expires 30d; #客户端缓存上述js,css数据30天 &#125;##add by 20140321#######nginx防sql注入#############start####if ( $query_string ~* &quot;.*[\;&apos;\&lt;\&gt;].*&quot; )&#123; return 444; &#125;if ($query_string ~* &quot;.*(insert|select|delete|update|count|\*|%|master|truncate|declare|\&apos;|\;|and|or|\(|\)|exec).* &quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;(cost\()|(concat\()&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]union[+|(%20)]&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]and[+|(%20)]&quot;) &#123; return 444; &#125;if ($request_uri ~* &quot;[+|(%20)]select[+|(%20)]&quot;) &#123; return 444; &#125;set $block_file_injections 0;if ($query_string ~ &quot;[a-zA-Z0-9_]=(\.\.//?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($query_string ~ &quot;[a-zA-Z0-9_]=/([a-z0-9_.]//?)+&quot;) &#123;set $block_file_injections 1;&#125;if ($block_file_injections = 1) &#123;return 448;&#125;set $block_common_exploits 0;if ($query_string ~ &quot;(&lt;|%3C).*script.*(&gt;|%3E)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;GLOBALS(=|\[|\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;_REQUEST(=|\[|\%[0-9A-Z]&#123;0,2&#125;)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;proc/self/environ&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;mosConfig_[a-zA-Z_]&#123;1,21&#125;(=|\%3D)&quot;) &#123;set $block_common_exploits 1;&#125;if ($query_string ~ &quot;base64_(en|de)code\(.*\)&quot;) &#123;set $block_common_exploits 1;&#125;if ($block_common_exploits = 1) &#123;return 444;&#125;set $block_spam 0;if ($query_string ~ &quot;\b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(erections|hoodia|huronriveracres|impotence|levitra|libido)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(ambien|blue\spill|cialis|cocaine|ejaculation|erectile)\b&quot;) &#123;set $block_spam 1;&#125;if ($query_string ~ &quot;\b(lipitor|phentermin|pro[sz]ac|sandyauer|tramadol|troyhamby)\b&quot;) &#123;set $block_spam 1;&#125;if ($block_spam = 1) &#123;return 444;&#125;set $block_user_agents 0;if ($http_user_agent ~ &quot;Wget&quot;) &#123; set $block_user_agents 1;&#125;# Disable Akeeba Remote Control 2.5 and earlierif ($http_user_agent ~ &quot;Indy Library&quot;) &#123;set $block_user_agents 1;&#125;# Common bandwidth hoggers and hacking tools.if ($http_user_agent ~ &quot;libwww-perl&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetRight&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GetWeb!&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go!Zilla&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Download Demon&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;Go-Ahead-Got-It&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;TurnitinBot&quot;) &#123;set $block_user_agents 1;&#125;if ($http_user_agent ~ &quot;GrabNet&quot;) &#123;set $block_user_agents 1;&#125;if ($block_user_agents = 1) &#123;return 444;&#125;###end#### location ~ ^/list &#123; #如果后端的服务器返回502、504、执行超时等错误，自动将请求转发到upstream负载均衡池中的另一台服务器，实现故障转移。 proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_cache cache_one; #对不同的HTTP状态码设置不同的缓存时间 proxy_cache_valid 200 301 302 304 1d; #proxy_cache_valid any 1d; #以域名、URI、参数组合成Web缓存的Key值，Nginx根据Key值哈希，存储缓存内容到二级缓存目录内 proxy_cache_key $host$uri$is_args$args; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $remote_addr; proxy_ignore_headers &quot;Cache-Control&quot; &quot;Expires&quot; &quot;Set-Cookie&quot;; #proxy_ignore_headers Set-Cookie; #proxy_hide_header Set-Cookie; proxy_pass http://backend_server; add_header Nginx-Cache &quot;$upstream_cache_status from km&quot;; expires 1d; &#125; access_log /data1/logs/abc.com.log access; #nginx访问日志 &#125;-----------------------ssl（https）相关------------------------------------server &#123; listen 13820; #监听端口 server_name localhost; charset utf-8; #gbk,utf-8,gb2312,gb18030 可以实现多种编码识别 ssl on; #开启ssl ssl_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/server.crt; #服务的证书 ssl_certificate_key /ls/app/nginx/conf/mgmtxiangqiankeys/server.key; #服务端key ssl_client_certificate /ls/app/nginx/conf/mgmtxiangqiankeys/ca.crt; #客户端证书 ssl_session_timeout 5m; #session超时时间 ssl_verify_client on; # 开户客户端证书验证 ssl_protocols SSLv2 SSLv3 TLSv1; #允许SSL协议 ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP; #加密算法 ssl_prefer_server_ciphers on; #启动加密算法 access_log /lw/logs/nginx/dataadmin.test.com.ssl.access.log access ; #日志格式及日志存放路径 error_log /lw/logs/nginx/dataadmin.test.com.ssl.error.log; #错误日志存放路径&#125;-------------------------------------------------------------------------&#125;]]></content>
      <categories>
        <category>Nginx</category>
        <category>Nginx配置详解</category>
      </categories>
      <tags>
        <tag>Nginx配置详解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对象的回收和分配]]></title>
    <url>%2F2019%2F03%2F17%2F%E5%AF%B9%E8%B1%A1%E7%9A%84%E5%9B%9E%E6%94%B6%E5%92%8C%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[GC算法 2019年3月17日 12:32 简介:由内存模型可知,虚拟机栈,本地方法栈,程序计数器都是线程私有的,伴随着线程的结束而消失.其中虚拟机栈和本地方法栈中的栈桢也会随着方法的进入和退出而进行着入栈和出栈的操作.每一个栈桢需要的内存基本上是在类结构确定下来后就确定了.因此内存的回收和分配都具有确定性,因此不需要过多考虑.但是在java堆和方法区,由于是动态加载,只有在运行期才会知道需要分配和回收的内存.因此,垃圾回收器所关注的也是这部分的内存. 判断对象已死?要进行对象回收首先要确定对象是否已死,目前有以下几种方式: 1. 引用计数算法:为每个对象添加一个引用计数器,每有一个地方引用,就加1,引用失效就减1.当为0时,则判为死亡.此方法在两个对象相互引用时,无法用此算法清除. 2. 可达性分析算法:通过一个GC root的根节点,往下搜索,如果搜索不到,则为死亡. 在java中,可作为GC roots的对象有: a. 虚拟机栈中的栈桢中局部变量表所引用的对象. b. 方法区中静态类属性所引用的对象. c. 方法区中的常量所引用的对象. d. 本地方法栈中native方法所引用的对象. 3. java中的引用a. 强引用: 例如:Object obj= new Object();只要引用还存在,永远不会GC. 用途:对象的默认状态. b. 软引用: 用SoftReference类来实现,被软引用关联的对象,在内存溢出发生之前,会对这部分进行回收. 用途:对象缓存. c. 弱引用 用WeakReference类实现,无论是否会发生内存溢出,在GC的时候,都会清除. 用途:对象缓存. d. 虚引用 用PhantomReference类实现.唯一目的是在这些对象被回收之前,会得到一个系统通知. 用途:垃圾回收监控. 4. Finallize()方法只会被系统调用一次,有不确定性,并且代价极大.建议用try-finally来代替. GC算法1. 标记-清除法首先标记出对象,然后统一回收.缺点是:效率低.并会产生大量不连续的内存碎片. 2. 复制法将内存分为两块,每次讲需要回收的对象放到一块,然后统一清理.缺点是:活跃内存减少一半,代价极大. 3. 复制法进阶版由于新生代对象具有极高的死亡率,因此将内存按照8:1的比例划分为一个大的Eden和2个小的survivor空间.每次使用的是Eden空间和一个survivor空间.在进行回收时,将活着的对象复制到那个暂时不用的survivor空间中.然后清理掉Eden空间和survivor空间.这样基本上只会浪费10%的内存空间.这种方式只适用于新生代. 4. 标记-整理算法​ 将活着的对象移动到一块,然后清理掉后面的对象.适用于老年代. 内存的分配策略:1. 新生代的Eden区分配大多数情况下,对象在新生代的Eden区分配,内存不足时,发起一次Minor GC 2. 大对象直接进入老年代.需要注意的是,避免编写短命的大对象. 3. 长期存活的对象直接进入老年代.每个对象都有一个年龄计数器(Age),在Eden出生,在第一次Minor GC下仍存活,并且被survivor所接受的话,就会移动到survivor中,年龄设为1.每次熬过一次Minor GC,年龄就加1,直到默认的15岁后,便会移动到老年代. 4. 动态对象年龄判断如果13岁的对象所占的空间大于survivor空间的一般,则会吧13的也放到老年代. 5. 空间分配担保当新生代在进行一个Minor GC后,仍有大量对象存活.将会将survivor空间无法容纳的对象直接进入老年代.在每次发生Minor GC 之前,都会检查之前每次晋升到老年代的平均大小,如果大于,便会改为一个Full GC.]]></content>
      <categories>
        <category>jvm</category>
        <category>对象的回收和分配</category>
      </categories>
      <tags>
        <tag>GC算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之内存模型]]></title>
    <url>%2F2019%2F03%2F17%2Fjvm%E4%B9%8B%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介:由于java将内存的管理交给了虚拟机,了解内存结构,有利于排查内存溢出和泄露问题. jdk1.8之后,hotspot的jvm改动: 使用内存中的元空间代替原先的方法区. 字符串常量池放进堆中. jvm运行时的数据区域:程序计数器: 一块很小的内存区域,主要作用是当前线程所执行字节码的行号指示器.字节码解释工作是,根据改变程序计数器的值来选取下一条所执行的字节码指令.例如:分支,循环,跳转,异常处理.因为jvm多线程是通过线程轮流切换来实现的,因此程序计数器是线程私有的. 如果是正在执行java方法,此区域存储的是正在执行的虚拟机的字节码指令.如果是native方法,此区域为undefined.程序计数器是唯一一片不会出现outofmemoryerror的区域. java虚拟机栈 描述的是方法的执行的内存模型,每一个方法的执行都会创建一个栈桢,用于存储局部变量表,操作数栈,动态连接,方法出口信息. 局部变量表 ​ 存储着编译期可知的基本数据类型,对象引用.基本单位是32个字节的slot,long和double会用2个slot存储,因此不具有原子性,但是由于是线程私有的,所以不具有安全问题.所需的空间在编译期就可以确定. ​ 常出现的异常: ​ ①.stackOverFlowError:请求的栈深度大于所允许的深度. ​ ②.OutMemoryError:虚拟机栈允许动态扩展的情况下,无法申请到足够的内存. 操作数栈 一个先进后出的栈,主要处理运算操作. 例如: 123int a= 1;int b= 2;int count = a+b; 过程: ① 压入 1. ② 压入 2. ③ 执行iadd命令,将栈顶的2个元素相加,即1+2. 本地方法栈和虚拟机栈的区别是: 虚拟机栈是为java方法提供服务,而本地方法栈则是为了native方法提供服务. java堆(重点) 是java虚拟机所管理的最大的一块内存区域.被所有线程共享.唯一目的是存放对象的实例.按照java虚拟机规范:堆中存放着所有的对象实例和数组信息.后续技术更加成熟也有稍微变化的地方. java堆是垃圾收集器管理的主要区域.因此称为GC堆.按照内存回收方面看,可以分为新生代和老年代.比例默认是1/3新生代,2/3老年代. java堆可以存放在不连续的内存空间,只要是逻辑上连续即可.当无法分配更多的实例时,会抛出OutOfMemoryError. 元空间 主要是存放被虚拟机加载的类的信息,常量,静态变量,编译后的代码. jdk1,8之后出现的,主要在本机内存中,更方便了根据情况扩容. 运行时的常量池 运行期的常量池是堆的一部分,用于存放编译期生成的字面量和符号引用. 需要注意的是和局部变量表的局别.同样是存储编译期的数据,不过一个是方法的参数,方法内定义的变量.另一个是存储字面量的常量. 直接内存直接内存不是jvm的内存.是介于本地方法栈中的native方法,与java堆之间的一种机器中的内存.例如在native方法进行io流的时候进行缓存数据的区域.是实现NIO的主要地方. 对象的访问在了解了虚拟机运行时候的数据区域后,下面来看下是如何进行对象访问的. 例如: Object obj = new Object(); 假设这块方法出现在方法体中,其中Object obj会映射到虚拟机栈的栈桢的局部变量表中的reference类型. new Object()则会映射到java堆中.另外java堆中还必须能够查到次对象类型的数据(对象的类型,父类,实现的接口,方法),这些数据存放在方法区.其中reference方法是如何定位到java堆中的?主要有2种方式: 句柄池访问: 屏幕剪辑的捕获时间: 2019/3/16 12:38 在java堆中划分出一块内存作为句柄池,reference存储的是句柄池的地址.句柄池内存储着对象实例的数据和对象类型的数据. 主要优点是:对象进行移动时,只需要改变句柄池中的对象实例信息. 直接指针访问方式 reference存储的是对象实例的数据,这是就要考虑如何放置对象类型的数据的地址.主要优点是节省了一次指针的定位,速度更快.sun 的hotspot所用的虚拟机主要是采用此方案. OOM异常java堆溢出通过-Xms指定最小值,-Xmx指定最大值 提示是java heap space,查看对象信息,确定是否是要用的,如果对象必须要或者,则是内存溢出,此时加大虚拟机内存.如果对象不必须活着,则是内心泄露,此时定位到对象点,进行处理. 虚拟机栈和本地方法栈溢出通过-Xss128k,表示指定大小为128k,主要有2种异常 线程请求的深度大于虚拟机允许的最大深度:Stack OverflowError. 虚拟机在扩展栈时,无法请求到足够的内存:OOM 运行时常量池溢出方法区内存,指定大小和方法区一致.提示信息是:PermGen space . 方法区溢出(1.8之后移除)通过-XX:PerSize和-XX:MaxPermSize指定大小,提示信息是:PermGen space ,方法区主要存储的是Class的信息,如类名,修饰符,常量池,字段描述,方法描述等.(1.8之后已经失效) 元空间在jdk1.8之后,hotspot对jvm架构进行了改变,将类的元数据放在了本地内存里面,静态变量和常量池放在了java堆中,移除了永久代,元数据是描述数据之间的关系的数据,其表现形式是1.5之后的注解,1.5之前的xml文件.由于在本地内存中,可以避免两个项目引用了同样的jar包,会出现大量的相同类信息引发的oom异常.避免了与老年代的资源竞争. 可用-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize指定元数据大小 本机直接内存溢出通过-XX:MaxDirectMemorySize指定大小,仅是抛出OOM溢出.]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm内存模型</category>
      </categories>
      <tags>
        <tag>java内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之字节码执行引擎]]></title>
    <url>%2F2019%2F03%2F04%2Fjvm%E4%B9%8B%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[概述从宏观上来说,java虚拟机的执行引擎基本上都是按照输入字节码,字节码解析,输出执行结果.从概念模型上来说,分为方法的调用和字节码的执行.下面详细描述: 运行时的栈桢结构2.1 简介栈桢是支持方法调用和字节码执行的数据结构.他是虚拟机运行时数据区的虚拟机栈的栈元素.栈桢存储着局部变量表,操作数栈,动态连接和方法返回地址等信息.每一个方法的调用到完成都对应着虚拟机栈的入栈到出栈的过程.在代码编译的时候,栈桢的深度就已经确定了,因此一个栈需要多少内存,不会受到运行期数据的影响. 在活动线程中,只有最顶层的当前栈桢是有效的.引擎中所有的字节码指令都是针对当前栈桢的. 2.2 局部变量表一组变量值存储空间.用于存放方法的参数和方法内部定义的变量.最小单位是slot.一个slot可以存放32位的数据类型,比如:short,byte,boolean,char,float,int,refearce(对象实例的引用).而对于64位的long和double,则会使用2个连续的slot来存储. 注意:java中的long和double都是非原子性的,在32位操作系统上,即读写都是分离的.每次读32位数据.因此在高并发性,需要volatile关键字标注. 但是在局部变量表里面,局部变量表是建立在线程的栈桢上,单线程私有,因此不会要安全问题. slot顺序: 虚拟机通过索引使用局部变量表.方法在执行时,第0位索引是当前实例变量的引用,即this关键字.其余则会按照顺序排序. 为节省栈桢空间,slot是可以重复使用的.即一个变量即使后续确定不再使用,则也不会立即回收其空间. 对一个变量赋值null使其被回收是没有意义的,因此在经过JIT编译器后,赋值null的操作会被清除掉. 局部变量表没有在类加载准备阶段对变量赋值,因此如果不赋值,会在编译期间报错. 2.3 操作数栈操作栈是一个先入后出的栈.可存储任意类型的数据.32位的栈容量为1,64位的为2.操作栈的深度不会超过max_stacks的值.在方法执行的时候,操作栈是空的,随着方法的执行,不断进行入栈和出栈操作. 例子:int a +int b ,在执行时a和b在栈顶的2个位置,然后字节码指令iadd,栈顶2个元素出栈,则会对其相加,然后将结果入栈. 在概念模型中,两个栈是独立的,但是虚拟机做了一些处理,2个栈可能会共享一部分数据.以便在调用方法时,无需再进行参数的复制传递.称之为:基于栈的执行引擎. 2.4 动态连接 每个栈桢都包含一个指向运行期常量池中该栈桢所属方法的引用.这个引用是为了动态连接. 2.5 方法返回地址 方法开始执行后,会有2条退出指令. ① 正常退出:遇到方法返回的字节码指令.栈桢中存储了PC计数器的值,作为返回地址 ② 异常退出: athrow 字节码指令.通过异常处理器表来确定返回地址. 方法调用方法调用不是方法执行,方法调用唯一的任务是确定调用那个方法.因为在编译阶段,没有连接过程,只是进行了符号引用,而没有真正分配内存布局的入口地址(直接引用).这个特性给java带来了强大的动态加载能力,只有在类加载期间,甚至是执行期间才能确定目标方法的直接引用. 3.1 解析:在解析阶段,会有一部分符号引用变为直接引用: 包括:静态方法,私有方法,实例构造器,父类方法4中.再加上final修饰的方法 3.2 分派① 静态分派:依靠静态类型来执行方法执行版本的分配动作.典型的应用是方法的重载,会自动加载适合的版本. ② 动态分派:典型额应用是方法的重写.即在运行期才会确定方法执行的版本.]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm之字节码执行引擎</category>
      </categories>
      <tags>
        <tag>字节码执行引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 1.8新特性之Lambda和Stream]]></title>
    <url>%2F2019%2F03%2F04%2FJDK8%E4%B9%8BLambda%E4%B8%8EStream%2F</url>
    <content type="text"><![CDATA[JDK 1.8新特性之Lambda和Stream1.Lambda表达式1.1 lambda简介lambda是为了简化代码,代替一些匿名类而推出的. 1.2公式123456(Type1 param1, Type2 param2, ..., TypeN paramN) -&gt; &#123; statment1; statment2; //............. return statmentM;&#125; 1.3 用例1 创建线程12345678910// Java 8之前：new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;Before Java8, too much code for too little to do&quot;); &#125;&#125;).start();//Java 8方式：new Thread( () -&gt; System.out.println(&quot;In Java8, Lambda expression rocks !!&quot;) ).start(); 2 列表的循环12345678910111213// Java 8之前：List features = Arrays.asList(&quot;Lambdas&quot;, &quot;Default Method&quot;, &quot;Stream API&quot;, &quot;Date and Time API&quot;);for (String feature : features) &#123; System.out.println(feature);&#125;// Java 8之后：List features = Arrays.asList(&quot;Lambdas&quot;, &quot;Default Method&quot;, &quot;Stream API&quot;, &quot;Date and Time API&quot;);features.forEach(n -&gt; System.out.println(n)); // 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，// 看起来像C++的作用域解析运算符features.forEach(System.out::println); 3 结合函数式接口Predicate1234567891011121314151617181920212223242526public static void main(args[])&#123; List languages = Arrays.asList(&quot;Java&quot;, &quot;Scala&quot;, &quot;C++&quot;, &quot;Haskell&quot;, &quot;Lisp&quot;); System.out.println(&quot;Languages which starts with J :&quot;); filter(languages, (str)-&gt;str.startsWith(&quot;J&quot;)); System.out.println(&quot;Languages which ends with a &quot;); filter(languages, (str)-&gt;str.endsWith(&quot;a&quot;)); System.out.println(&quot;Print all languages :&quot;); filter(languages, (str)-&gt;true); System.out.println(&quot;Print no language : &quot;); filter(languages, (str)-&gt;false); System.out.println(&quot;Print language whose length greater than 4:&quot;); filter(languages, (str)-&gt;str.length() &gt; 4);&#125; public static void filter(List names, Predicate condition) &#123; for(String name: names) &#123; if(condition.test(name)) &#123; System.out.println(name + &quot; &quot;); &#125; &#125;&#125; 4.Lambda中this的概念Lambda中的this指的是声明它的外部对象,不是闭包里面的. 1234567891011121314151617181920212223242526public class WhatThis &#123; public void whatThis()&#123; //转全小写 List&lt;String&gt; proStrs = Arrays.asList(new String[]&#123;&quot;Ni&quot;,&quot;Hao&quot;,&quot;Lambda&quot;&#125;); List&lt;String&gt; execStrs = proStrs.stream().map(str -&gt; &#123; System.out.println(this.getClass().getName()); return str.toLowerCase(); &#125;).collect(Collectors.toList()); execStrs.forEach(System.out::println); &#125; public static void main(String[] args) &#123; WhatThis wt = new WhatThis(); wt.whatThis(); &#125;&#125;输出：com.wzg.test.WhatThiscom.wzg.test.WhatThiscom.wzg.test.WhatThisnihaolambda 1.4 性能对比1. 遍历66万个对象对比.1234567891011121314151617ArrayList&lt;user&gt; objects = new ArrayList&lt;&gt;(); for(int i1=0;i1&lt;666666;i1++)&#123; objects.add(new user(&quot;dcx&quot;,&quot;12&quot;)); &#125; System.out.println(&quot;对象大小是:&quot;+objects.size()); long start = System.currentTimeMillis(); objects.forEach (n-&gt; &#123; System.out.println(n.name); &#125;); long end = System.currentTimeMillis(); long start1 = System.currentTimeMillis(); for (user u:objects)&#123; System.out.println(u.name); &#125; long end1 = System.currentTimeMillis(); System.out.println(&quot;lambda耗时=&quot;+ (end-start)); System.out.println(&quot;普通方法耗时=&quot;+ (end1-start1)); 结果: 12lambda耗时=2978普通方法耗时=2971 1.5 函数式接口为了支持Lambda表达式,推出了函数式接口,注解是@FunctionInterface,其本质是一个接口.个人理解是,先定义一个数学中的公式(y=x+b),然后,在使用的时候,直接通过接口使用,而不用去实现这个接口. 1.特点a.只能有一个抽象方法. b.可以定义静态方法. c.可以定义一个或者多个默认方法. 2.demo//目前研究较浅,具体使用例子还无法定位. 1234567891011121314151617181920@FunctionalInterfacepublic interface AvageUtil&lt;Y,X,A&gt; &#123; Y avage(X x,A a); //求平均值 default int avager(int x,int a)&#123; return (a+x)/2; &#125; static void demo(int a)&#123; System.out.println(a); &#125; public static void main(String[] args) &#123; AvageUtil avageUtil=(x,a)-&gt;(int) x+ (int) a; //结果是8 System.out.println(avageUtil.avage(3,5)); //结果是4 System.out.println(avageUtil.avager(3,5)); //结果是3 AvageUtil.demo(3); &#125;&#125; 3.jdk中的函数式接口1.对于单个入参 1234567891011121314151617181920212223242526272829public class FunctionalInterfaceMain &#123; public static void main(String[] args) &#123; //接收一个T类型的参数，返回一个R类型的结果 Function&lt;String,String&gt; function1 = item -&gt; item +&quot;返回值&quot;; // 接收一个T类型的参数，不返回值 Consumer&lt;String&gt; function2 = iterm -&gt; &#123;System.out.println(iterm);&#125;;//lambda语句，使用大括号，没有return关键字，表示没有返回值 // 接收一个T类型的参数，返回一个boolean类型的结果 Predicate&lt;String&gt; function3 = iterm -&gt; &quot;&quot;.equals(iterm); //不接受参数，返回一个T类型的结果 Supplier&lt;String&gt; function4 = () -&gt; new String(&quot;&quot;); /** * 再看看怎么使用 * demo释义： * 1、创建一个String类型的集合 * 2、将集合中的所有元素的末尾追加字符串&apos;1&apos; * 3、选出长度大于2的字符串 * 4、遍历输出所有元素 */ List&lt;String&gt; list = Arrays.asList(&quot;zhangsan&quot;,&quot;lisi&quot;,&quot;wangwu&quot;,&quot;xiaoming&quot;,&quot;zhaoliu&quot;); list.stream() .map(value -&gt; value + &quot;1&quot;) //传入的是一个Function函数式接口 .filter(value -&gt; value.length() &gt; 2) //传入的是一个Predicate函数式接口 .forEach(value -&gt; System.out.println(value)); //传入的是一个Consumer函数式接口 &#125; &#125; 2.对于多个入参 1234567891011121314151617181920212223242526272829303132333435363738394041public class FunctionalInterfaceTest &#123; public static void main(String[] args) &#123; /** * Bi类型的接口创建 */ //接收T类型和U类型的两个参数，返回一个R类型的结果 BiFunction&lt;String, String, Integer&gt; biFunction = (str1,str2) -&gt; str1.length()+str2.length(); //接收T类型和U类型的两个参数，不返回值 BiConsumer&lt;String, String&gt; biConsumer = (str1,str2) -&gt; System.out.println(str1+str2); //接收T类型和U类型的两个参数，返回一个boolean类型的结果 BiPredicate&lt;String, String&gt; biPredicate = (str1,str2) -&gt; str1.length() &gt; str2.length(); /** * Bi类型的接口使用 */ int length = getLength(&quot;hello&quot;, &quot;world&quot;, (str1,str2) -&gt; str1.length() + str2.length()); //输出10 boolean boolean1 = getBoolean(&quot;hello&quot;, &quot;world&quot;, (str1,str2) -&gt; str1.length() &gt; str2.length()); //输出false System.out.println(length); System.out.println(boolean1); noResult(&quot;hello&quot;, &quot;world&quot;, (str1,str2) -&gt; System.out.println(str1+&quot; &quot;+str2)); //没有输出 &#125; public static int getLength(String str1,String str2,BiFunction&lt;String, String, Integer&gt; function)&#123; return function.apply(str1, str2); &#125; public static void noResult(String str1,String str2,BiConsumer&lt;String, String&gt; biConcumer)&#123; biConcumer.accept(str1, str2); &#125; public static boolean getBoolean(String str1,String str2,BiPredicate&lt;String, String&gt; biPredicate)&#123; return biPredicate.test(str1, str2); &#125;&#125; 2.stream API1.stream是什么?stream是元素的集合,可以类比于iterator,并可以支持顺序或者并行的对原stream进行汇聚的操作.相比于iterator的逐个去操作每个集合的元素,stream支持对所有元素的一口气操作.比如:求平均值,找出大于10的个数等等. 2.操作流程示例//找出大于3的个数 12List&lt;Integer&gt; nums = Lists.newArrayList(1,2,3,4,5,6);nums.stream().filter(num -&gt; num &gt;3).count(); 3.创建1.通过Stream的静态工厂方法. 2.通过collection接口的方法.col.stream(). 4.功能 主要针对的是对Collection集合的操作.详情可看Stream源码. 4.性能对比//求平均值,6千万个数据 123456789101112131415161718ArrayList&lt;Integer&gt; objects = new ArrayList&lt;&gt;(); for (int i=0;i&lt;66666666;i++)&#123; objects.add(i); &#125; //求平均值 //传统循环 long start = System.currentTimeMillis(); long n=0; for (int i=0;i&lt;objects.size();i++)&#123; n+=objects.get(i); &#125; System.out.println(n/objects.size()); System.out.println(&quot;传统方式耗时:&quot;+(System.currentTimeMillis()-start)); //stream API long start1 = System.currentTimeMillis(); IntSummaryStatistics intSummaryStatistics = objects.stream().mapToInt((x) -&gt; x).summaryStatistics(); System.out.println(intSummaryStatistics.getAverage()); System.out.println(&quot;stream API 耗时:&quot;+(System.currentTimeMillis()-start1)); 结果:stream耗时会比传统方法长. 123433333332传统方式耗时:1263.33333325E7stream API 耗时:195]]></content>
      <categories>
        <category>java基础</category>
        <category>JDK1.8</category>
      </categories>
      <tags>
        <tag>Lambda</tag>
        <tag>Stream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm类加载机制]]></title>
    <url>%2F2019%2F03%2F04%2Fjvm%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1.概述得知class文件是一段规则有序的二进制流后,类加载流程简述是: 虚拟机将二进制流加载到内存,对数据进行校验,转换解析和初始化,最后形成可以直接被虚拟机使用的java类型. 需要注意的是,java的类型的加载,连接,初始化都是在运行期执行的,从而提供了动态扩展的特性. 由于动态加载的特性,其中解析动作不一定在初始化之前执行. 2.类加载过程2.1 加载① 通过一个类的权限定名称获取这个类的二进制字节流 ② 将这个字节流所代表的静态存储结构转化为方法区的运行时的数据结构 ③ 在内存中生成一个java.lang.class对象,作为方法区这个类的各种数据的访问接口 注: 在类创建的时候,并不包括数组,数组是由java虚拟机直接创建的,不经过类加载器. 但是数组中的元素类型,则会通过类加载器创建. 2.2 验证验证主要是保证字节流中的信息不回危害虚拟机本身,并且符合虚拟机的规范要求.主要有4个方面的验证: ① 文件格式验证: 对开头的二进制魔数进行验证,对主版本号的验证,等等. 目的是保证二进制能够正确解析,存到方法区之内. ② 元数据验证:是否符合java语言规范,比如继承了一个被final修饰的类. ③ 字节码验证: 通过分析数据流和控制流,确定语义是否合法并且符合逻辑. ④ 符号引用验证: 可以看做是对类自身外的信息进行的匹配性校验,比如:是否可以通过权限定名找到相应的类,或者符号引用中的方法字段的可访问性,是否为public或者private等. 2.3 准备此阶段是为类变量分配内存并设置初始值的阶段.这里分配的内存都在方法区进行.并且只会实例化static修饰的变量.类实例变量会在进行类初始化的时候,分配在堆内存中.需要注意的是,private static int a=1;在这句代码中设置的初始值为0,并不是1, ①在类进行初始化后,会为1. ② private static final int a=1,这时也是1. 下面是基本数据类型的零值(准备阶段初始值): 2.4 解析将符号引用变换为直接引用. ① 符号引用: 和内存无关,一组用来描述所引用目标的一组符号. ② 直接引用: 和内存有关,直接引用的数据,在内存中肯定存在.可以是指针,偏移量或者句柄. 主要解析的符号引用为: （1） 类或者接口 （2） 字段 （3） 类方法 （4） 接口方法 （5） 方法类型 （6） 方法句柄 （7） 调用点限定符 2.5 初始化根据java类中的代码进行初始化.也可以说是执行类构造器()方法的执行过程. 类构造器()的具体流程是: （1） 由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生. （2） 和类构造函数不同,不会去调用父类构造器,因为虚拟机会保证父类构造器在子类之前,肯定会执行完.因此第一个执行的类构造器是java.lang.Object. （3） 如果一个类中没有静态语句块和变量赋值操作,则不会生成类构造器. （4） 接口中的如果没有用到父类的变量,则不会生成父类构造器. （5） 虚拟机会保证类构造器在多线程环境下的加锁与同步. 3.类加载器3.1 概述通过一个类的全限定名称来获取类的二进制流的动作 3.2 类与类加载器一个类的唯一性是由同一个类加载器和和这个类本身共同决定的. 一个简单的类加载器: 用这个类加载器和系统加载出来的类,不是同一个类. 3.3 双亲委派模型对于java开发人员来说,有3种系统提供的类加载器: （1） 启动类加载器(bootstrap classLoder):加载/lib下的类,不能被java程序直接引用 （2） 扩展类加载器(extension_classLoder): 由sun.misc.Launcher$ExtClassLoder实现,加载/lib/ext下的类,java程序可以直接使用 （3） 应用程序类加载器(Application classLoder): 由sun.misc.Launcher$app-ClassLoder实现,加载用户类路径下的类.可以直接使用,并且默认类加载器为这个 类加载器层次的关系可以用双亲委派模型来说明,不过层级间不是父子继承关系,而是组合关系.当然这个关系模型是java设计者所推荐的模型. 双亲委派工作流程是: 当一个类加载器接收到加载类的请求时,不会立马去加载这个类,而是将这个请求委派给父类,一直到启动类加载器.当父类无法搜索到这个类时,最终类加载器才会去加载. 3.4 双亲委派模型的破坏1) 在这个模型出现之前,可以继承java.lang.ClassLoder,重写loadClass(),后续建议只有在loadClass()加载失败后,然后再去加载自己的类. 2) 线程上下文类加载器的出现.线程还没创建时,他是父类加载器,如果全局没有设置,则会默认为应用加载器.从而实现了父类加载器请求子类去加载类.所有的SPI操作都是这个原理,比如常见的jdbc,jndi 3) 热部署话等动态的追求,OSGN的java模块化标准.使得每一个模块都有独自的类加载器.双亲委派模型成为一个网状结构,收到类加载请求时,按照以下的标准执行:]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm类加载机制</category>
      </categories>
      <tags>
        <tag>类加载机制</tag>
        <tag>双亲委派模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jvm之类文件结构]]></title>
    <url>%2F2019%2F03%2F04%2F%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[1.1 机器码与字节码①机器码(Native code): 可由CPU直接读取操作的机器指令.处于最底层,不需要编译.速度最快.不可跨平台.依靠硬件存在. ②字节码:是一种中间码，它比机器码更抽象，需要直译器转译后才能成为机器码的中间代码。依靠平台存在. 以前用机器码操作系统，现在是用字节码操作机器码，进一步操作系统,使得语言跨平台成为可能. 1.2.跨平台原理:java语言一如既往的保持着”一次编写,到处运行的特性”,依靠的就是其JVM.JVM不关注语言的来源,只关注的是”CLASS 二进制文件”,只要符合JVM的类的编写规范,就可以经过JVM进行字节码到机器码的转换. 因此, 功能性比较: java或者其他语言&gt;字节码&gt;机器码 速度上:相反 1.3.class文件结构简介:1.3.1.class内容格式Class文件是一组以8位字节为单位的二进制流,各个数据项目以严格的顺序紧凑的排列在CLass文件中,中间没有分隔符.因此文件中的数据全是必要的数据.当遇到需要占用8个字节以上的数据时,则会按照高位在前的方式分割为若干个8位字节进行存储. ①.高位在前,高位字节在地址最低位 例如:32位下,int i=10 低位在前为: 00001010 00000000 00000000 00000000 而在高位优先的内存中： 00000000 00000000 00000000 00001010 字节码本身是无序的,需要有一定的规则去读取数据,高位优先更符合人的操作习惯,但是在X86处理器采用的是低位优先的规则. 1.3.2.class 结构CLass文件中定义了类似于C语言的2种数据类型:无符号数和表. ①.无符号数是最基本的数据类型,用u1,u2,u4,u8分别表示1,2,3,8个字节. ②.表是由无符号数和表构成的复合数据类型.习惯性的以”_info”结尾. 因此Class文件本质上是由众多无符号数组成的一张表. 下面贴上一张结构组成图: 因此,一个class里面会有1个4个字节的magic+1个2个字节的minor_version……..组成.其中具体含义后续详细介绍. 1.3.2.1 magic 魔数在对一个文件进行类型判断时,比如是.png还是.jpg,文件存储标准中都会使用魔数来进行判断.同样,判断是否为一个class文件,也使用了这个标准.对于class文件,开头的前4个字节为魔数,值为:0XCAFEBABE,用来表示这是一个class文件.紧接着魔数后面的4个字节存储着class文件的版本号,5,6位次版本号,7,8是主版本号.高版本的JDK会向下兼容以前版本的class文件,但是会拒绝执行超过其版本的class文件,即使文件格式没有发生变化. 对一个class文件,用16进制编辑器打开,可以看到上面的结果. 第一行的0xCAFEBEBE为文件类型标志,5,6为0x0000次版本号,7,8为0x0032,十进制为50,表示可被1.6以上的jdk进行编译.下面是jdk和class文件版本对应表: 1.3.2.2 constant_pool (常量池)紧接着主版本号之后,便是常量池的入口,可以把常量池比作class文件的资源仓库.这是文件中第一个表数据结构,由于常量的个数不固定,所以在常量池前面会有一个u2类型的数据,constant_pool_count来表示类中定义的常量池的个数.不过常量池会将索引为0的位置留作备用,用来满足指向常量池的索引值需要表示为”不引用任何常量池”的意思.因此常量池的实际个数为constant_pool_count-1. 常量池主要有2中结构:字面量和符号引用. ①.字面量:java语言层面的常量,如文本字符串,final声明的常量等. ②.符号引用:编译方面的概念,主要有类和接口的全限定名,字段的名称和描述符,方法的名称和描述符. 在C/C++,会经历编辑,编译,链接,运行阶段,但是java中没有链接这一阶段,而是采用的是在虚拟机加载类文件的时候动态连接.意思是class文件中不会保存方法字段的占用内存信息,只有在运行期间进行转换才会得到.这部分内容在类加载机制中会详细说明. 常量池中每一个常量都是一张表,开始的第一位是u1类型的标志位,对应关系如下: 每个常量又都会有各自的结构组成, 具体class字节码分析工具,可以用jdk下的bin目录下,javap工具,通过执行: javap -verbose ttclass ​ 可将class转化为字节码,输出. 1.3.2.3 访问标志主要是用于标志一些类和接口层次的信息,占用2个字节 例如:一个普通的public类,access_flags的值为:0x0001+0x0020=0x0021 1.3.2.4 类索引,父类索引,接口索引访问标志后面是这些索引的信息,其中类索引和父类索引是一个u2类型的数据,接口索引是一组u2类型的数据. 顺序为:类索引+父类索引+接口索引大小+接口索引 1.3.2.5 字段表集合字段表是用于描述类或者接口中声明的变量.字段主要有类级变量和实例级变量,不包括方法内部声明的变量. 其中access_flag和类中的访问标志相似.可以设置的值如下: 然后name_index和descriptor_index分别代表了简单名称和描述符; 概念: ① 全限定名:类名中的点变成”/“,例如:org/da/dad/aa.class ② 简单名称: 没有类型和参数修饰的字段或者方法,inf()简称为inf ③ 描述符: 描述字段的数据类型.基本数据类型通常用一个大写字母表示,对象类型用”L+全限定名”来表示. 对于数组类型,一维数组使用[描述,例如int[],用’[I’表示.二维的用’[[‘表示,例如:Integer[][]用[[I表示. 后续的attribute_count和attribute只有在给字段添加默认值的时候,才会显示. 1.3.2.6 方法表集合字段表后面跟着的是方法表,两者很类似, 其中的访问标志选项为: 顺序为:方法数量+访问标志+…(结构体) 其中,方法里面的代码在编译成字节码后,会存放在方法属性表里面,对应的key为Code. 1.3.2.7 属性表集合和其他结构不同,属性表不要求有严格的顺序,长度和内容.只需要和已有的属性名不同即可. java虚拟机定义了21个预定义属性,详情可看书中,暂不一一列举. 对于每一个属性,都会用一个constant_utf8_info属性来表示. 其中简要说下Code属性: code属性是方法里面的代码编译后的字节码: ① attribute_name_index : constant_utf8_info的常量,固定值为”code”,表示属性名称. ② attribute_length: 属性长度,为6个字节. ③ max_stack: 操作栈的深度.java虚拟机会根据这个深度来分配. ④ max_locals: 局部变量表所需要的空间. ⑤ code_length ,code: java源文件编译后的字节码指令. 1.4 字节码指令java虚拟机的指令是由一个字节的,代表某种操作含义的数字(操作码)+(0,n)个代表此操作所需的参数(操作数)组成.但是由于java虚拟机的架构是面向操作数栈而不是面向寄存器的,因此一般都是只有一个操作码组成. 一个字节的操作码长度为:0-255. 因此java虚拟机的执行基础模型为: 1.4.1 字节码与数据类型 在java虚拟机指令集中,大多都会携带其操作所需的数据类型,但是并非所有的数据类型都会有对于的指令.会有一些单独的指令在必要的时候,将不支持的类型转化为支持的.大体上可划分为9个指令. 1.4.2 加载和存储指令主要将数据在栈帧中的局部变量表和操作数栈之间传输,主要包括: ① 将一个局部变量加载到操作栈:iload等; ② 将一个数值从操作栈存储到局部变量表: istore等 ③ 将一个常量加载到操作栈:bipush 1.4.3 运算指令用于对操作数栈上的数值进行某种运算,然后把结果存到栈顶. 注意:java虚拟机没有操作byte,boolean,short,char的指令,最后都会转化为int指令来特殊操作. 1.4.4 类型转化指令 java数据类型及其大小,在进行转化的时候,是默认支持小范围向大范围转化的.而在大范围向小范围转化时,需要进行强制转化. 1.4.5 对象的创建以及访问指令数组和类实例用到了不同的创建指令. 1.4.6 操作数栈管理指令和操作普通的堆栈一样,java虚拟机提供了用于直接操作操作数栈的指令: ① 出栈: pop,pop2 ② 复制栈顶数值,并重新压入栈顶,dup,dup2 ③ 将栈最顶端的2个值互换,swap 1.4.7 控制转移指令有条件或者无条件的修改寄存器的值: 1.4.8 方法调用和返回指令 1.4.9 异常处理指令显示抛出异常的语句,是由athrow指令实现,并且除了显示跑出异常,java虚拟机也会有一些指令进行异常检测. 处理异常(catch语句),没有字节码指令,这部分功能是由异常表来完成 1.4.10 同步指令包括2种同步方式,都是由管程(Monitor)支持: ① 方法级同步: 不通过字节码来操作,是在方法的调用和返回中实现. 流程是:从常量池中取出acc_synchronized得知是否为同步方法,如果是,当前线程则会持有管程,方法执行完后,释放管程.同一个管程只能在一个线程中存在. ② 同步一段指令集序列: 是由java语言的synchronized语句块表示,这个关键字由2个指令支持:monitorenter和monitorexit 例如: 以下代码的字节码为:]]></content>
      <categories>
        <category>jvm</category>
        <category>jvm之类文件结构</category>
      </categories>
      <tags>
        <tag>字节码</tag>
        <tag>字节码指令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java之线程,线程池]]></title>
    <url>%2F2019%2F03%2F03%2Fjava%E4%B9%8B%E7%BA%BF%E7%A8%8B-%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程与进程&nbsp;&nbsp; 进程是系统进行资源分配和调度的独立单位,一个进程下可以包括多个线程.一个进程在执行时,总需要多个子任务去执行,这就需要多线程.最大的利用CPU的空闲时间去执行更多的任务. 创建线程继承Thread类12345678910111213public class StringUtil extends Thread&#123; @Override public void run() &#123; System.out.println(this.getName()); super.run(); &#125; public static void main(String[] args) &#123; for(int i=0;i&lt;100;i++) &#123; new StringUtil().start(); &#125; &#125; &#125; 实现runnable接口123456789101112public class Aa implements Runnable&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; public static void main(String[] args) &#123; for(int i=0;i&lt;100;i++) &#123; new Thread(new Aa()).start(); &#125; &#125;&#125; 两种方法对比 看源码1234567891011121314151617publicclass Thread implements Runnable &#123; /* Make sure registerNatives is the first thing &lt;clinit&gt; does. */ private static native void registerNatives(); static &#123; registerNatives(); &#125; private volatile String name; private int priority; /* Whether or not the thread is a daemon thread. */ private boolean daemon = false; /* Fields reserved for exclusive use by the JVM */ private boolean stillborn = false; private long eetop; 在Thread源码中,Thread是Runnable的实现.因此可以得出, a) 我们如果使用继承Thread类,系统已经给我们经过继承,封装好了.可以直接使用. b) 我们如果直接使用实现Runnable接口方式,需要将我们的类放进Thread方法中,去生成一个Thread类,从而具有Thread的所有功能. 由于两种方法基本上是一样的,但是java是单继承的,为了不会影响到我们写的类去继承其他类,所以推荐使用第二种方法. 从demo可知,run()方法是线程中我们需要实现的业务.start()方法是开启一个线程. start()方法源码:1234567891011121314151617181920212223242526272829303132public synchronized void start() &#123; /** * This method is not invoked for the main method thread or &quot;system&quot; * group threads created/set up by the VM. Any new functionality added * to this method in the future may have to also be added to the VM. * * A zero status value corresponds to state &quot;NEW&quot;. */ if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group&apos;s list of threads * and the group&apos;s unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; //开启线程 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125; &#125; &nbsp;&nbsp;可知真正开启一个线程的方法是start0(),并且在创建的时候,用synchronized关键字,进行锁住;同时,可知为了进行线程的管理,将创建的线程加入了线程组. Thread类 线程的方法（Method）、属性（Property） 1）优先级（priority） &amp;nbsp;&amp;nbsp;每个类都有自己的优先级，一般property用1-10的整数表示，默认优先级是5，优先级最高是10；优先级高的线程并不一定比优先级低的线程执行的机会高，只是执行的机率高；默认一个线程的优先级和创建他的线程优先级相同； 2）Thread.sleep()/sleep(long millis) &amp;nbsp;&amp;nbsp;当前线程睡眠/millis的时间（millis指定睡眠时间是其最小的不执行时间，因为sleep(millis)休眠到达后，无法保证会被JVM立即调度）；sleep()是一个静态方法(static method) ，所以他不会停止其他的线程也处于休眠状态；线程sleep()时不会失去拥有的对象锁。 作用：保持对象锁，让出CPU，调用目的是不让当前线程独自霸占该进程所获取的CPU资源，以留一定的时间给其他线程执行的机会； 3）Thread.yield() &amp;nbsp;&amp;nbsp; 让出CPU的使用权，给其他线程执行机会、让同等优先权的线程运行（但并不保证当前线程会被JVM再次调度、使该线程重新进入Running状态），如果没有同等优先权的线程，那么yield()方法将不会起作用。 4）thread.join() 使用该方法的线程会在此之间执行完毕后再往下继续执行。 5）object.wait() 当一个线程执行到wait()方法时，他就进入到一个和该对象相关的等待池(Waiting Pool)中，同时失去了对象的机锁—暂时的，wait后还要返还对象锁。当前线程必须拥有当前对象的锁，如果当前线程不是此锁的拥有者，会抛出IllegalMonitorStateException异常,所以wait()必须在synchronized block中调用。 6）object.notify()/notifyAll() 唤醒在当前对象等待池中等待的第一个线程/所有线程。notify()/notifyAll()也必须拥有相同对象 锁，否则也会抛出IllegalMonitorStateException异常。 7）Synchronizing Block Synchronized Block/方法控制对类成员变量的访问；Java中的每一个对象都有唯一的一个内置的锁，每个Synchronized Block/方法只有持有调用该方法被锁定对象的锁才可以访问，否则所属线程阻塞；机锁具有独占性、一旦被一个Thread持有，其他的Thread就不能再拥有（不能访问其他同步方法），方法一旦执行，就独占该锁，直到从该方法返回时才将锁释放，此后被阻塞的线程方能获得该锁，重新进入可执行状态。 注: 线程组是一个进程下所有的线程管理类,线程以树形的结构存储 线程池是为了管理线程的生命周期，复用线程，减少创建销毁线程的开销 继续查看:源码: 1private native void start0(); 可知最终是调用的原生C/C++方法去开启的一个线程. 线程池: ThreadPoolExecutor&nbsp;&nbsp;ThreadPoolExecutor是jdk1.5之后package java.util.concurrent;官方提供的线程池创建类.主要负责线程的调度,任务的执行,线程池的管理等. 构造方法: 12345678 public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler);&#125; 参数 说明 核心线程数. 线程池中一直保持存活的线程数. 最大线程数 线程池中活跃的最大线程数.对于cpu密集型的应用,设置为N+1,io密集型的应用,设置为2N+1.N为CPU核心数. 线程池队列 当核心线程数满了后,继续创建线程,会进入线程池队列中. 线程存活时间 超出核心线程数的多余的线程,在空闲时存活的的时间. 线程创建工厂 使用工厂模式,为线程池创建线程. 拒绝策略 在最大线程数也满了后,再次添加线程,则会拒绝,一般有4中策略. 重点讲解：其中比较容易让人误解的是：corePoolSize，maximumPoolSize，workQueue之间关系。 当线程池小于corePoolSize时，新提交任务将创建一个新线程执行任务，即使此时线程池中存在空闲线程。 当线程池达到corePoolSize时，新提交任务将被放入workQueue中，等待线程池中任务调度执行 当workQueue已满，且maximumPoolSize&gt;corePoolSize时，新提交任务会创建新线程执行任务 当提交任务数超过maximumPoolSize时，新提交任务由RejectedExecutionHandler处理 当线程池中超过corePoolSize线程，空闲时间达到keepAliveTime时，关闭空闲线程 当设置allowCoreThreadTimeOut(true)时，线程池中corePoolSize线程空闲时间达到keepAliveTime也将关闭 拒绝策略: a. AbortPolicy:丢弃线程,并抛异常.(默认) b. DiscardPolicy: 丢弃线程,不抛出异常, c. DiscardOldestPolicy: 丢弃最前面的线程,并尝试运行, d. CallerRunsPolicy: 由调用线程处理. 可见,多余的线程会被丢弃,可以自定义拒绝策略. ​ 官方给出了工具类Executors,package java.util.concurrent;,用来快速创建一些线程池方案. 构造一个固定线程数目的线程池，配置的corePoolSize与maximumPoolSize大小相同，同时使用了一个无界LinkedBlockingQueue存放阻塞任务，因此多余的任务将存在再阻塞队列，不会由 RejectedExecutionHandler处理 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; 构造一个缓冲功能的线程池，配置corePoolSize=0，maximumPoolSize=Integer.MAX_VALUE，keepAliveTime=60s,以及一个无容量的阻塞队列 SynchronousQueue，因此任务提交之后，将会创建新的 线程执行；线程空闲超过60s将会销毁 12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;()); &#125; 构造一个只支持一个线程的线程池，配置corePoolSize=maximumPoolSize=1，无界阻塞队列 LinkedBlockingQueue；保证任务由一个线程串行执行 123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;())); &#125; 构造有定时功能的线程池，配置corePoolSize，无界延迟阻塞队列DelayedWorkQueue；有意思的是： maximumPoolSize=Integer.MAX_VALUE，由于DelayedWorkQueue是无界队列，所以这个值是没有意义的 123456789101112public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize); &#125;public static ScheduledExecutorService newScheduledThreadPool( int corePoolSize, ThreadFactory threadFactory) &#123; return new ScheduledThreadPoolExecutor(corePoolSize, threadFactory); &#125;public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, TimeUnit.NANOSECONDS, new DelayedWorkQueue(), threadFactory); &#125; 注: 工具类中提供的创建线程池,所用的队列都是无界队列,因此会存在OOM问题,当然,也可以自定制自己的线程池方案,自定义拒绝策略:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----10 * maximumPoolSize 最大线程池大小----30 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(10)====10容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 10, 30, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(10), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; // 记录异常 // 报警处理等 System.out.println(&quot;error.............&quot;); &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println(&quot;提交第&quot; + i + &quot;个任务!&quot;); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;running=====&quot;); &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;方法中建立一个核心线程数为30个，缓冲队列有10个的线程池。每个线程任务，执行时会先睡眠3秒，保证提交10任务时，线程数目被占用完，再提交30任务时，阻塞队列被占用完，，这样提交第41个任务是，会交给CustomRejectedExecutionHandler 异常处理类来处理。&nbsp;提交任务的代码如下：123456789101112131415161718192021222324252627282930313233343536373839public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&apos;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) reject(command); &#125; 注意：41以后提交的任务就不能正常处理了，因为，execute中提交到任务队列是用的offer方法，如上面代码，这个方法是非阻塞的，所以就会交给CustomRejectedExecutionHandler 来处理，所以对于大数据量的任务来说，这种线程池，如果不设置队列长度会OOM，设置队列长度，会有任务得不到处理，接下来我们构建一个阻塞的自定义线程池 定制属于自己的阻塞线程池 :123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138package com.tongbanjie.trade.test.commons;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.ExecutorService;import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicInteger; public class CustomThreadPoolExecutor &#123; private ThreadPoolExecutor pool = null; /** * 线程池初始化方法 * * corePoolSize 核心线程池大小----1 * maximumPoolSize 最大线程池大小----3 * keepAliveTime 线程池中超过corePoolSize数目的空闲线程最大存活时间----30+单位TimeUnit * TimeUnit keepAliveTime时间单位----TimeUnit.MINUTES * workQueue 阻塞队列----new ArrayBlockingQueue&lt;Runnable&gt;(5)====5容量的阻塞队列 * threadFactory 新建线程工厂----new CustomThreadFactory()====定制的线程工厂 * rejectedExecutionHandler 当提交任务数超过maxmumPoolSize+workQueue之和时, * 即当提交第41个任务时(前面线程都没有执行完,此测试方法中用sleep(100)), * 任务会交给RejectedExecutionHandler来处理 */ public void init() &#123; pool = new ThreadPoolExecutor( 1, 3, 30, TimeUnit.MINUTES, new ArrayBlockingQueue&lt;Runnable&gt;(5), new CustomThreadFactory(), new CustomRejectedExecutionHandler()); &#125; public void destory() &#123; if(pool != null) &#123; pool.shutdownNow(); &#125; &#125; public ExecutorService getCustomThreadPoolExecutor() &#123; return this.pool; &#125; private class CustomThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread t = new Thread(r); String threadName = CustomThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1); System.out.println(threadName); t.setName(threadName); return t; &#125; &#125; private class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; try &#123; // 核心改造点，由blockingqueue的offer改成put阻塞方法 executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; // 测试构造的线程池 public static void main(String[] args) &#123; CustomThreadPoolExecutor exec = new CustomThreadPoolExecutor(); // 1.初始化 exec.init(); ExecutorService pool = exec.getCustomThreadPoolExecutor(); for(int i=1; i&lt;100; i++) &#123; System.out.println(&quot;提交第&quot; + i + &quot;个任务!&quot;); pool.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; System.out.println(&quot;&gt;&gt;&gt;task is running=====&quot;); TimeUnit.SECONDS.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; // 2.销毁----此处不能销毁,因为任务没有提交执行完,如果销毁线程池,任务也就无法执行了 // exec.destory(); try &#123; Thread.sleep(10000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; 解释：当提交任务被拒绝时，进入拒绝机制，我们实现拒绝方法，把任务重新用阻塞提交方法put提交，实现阻塞提交任务功能，防止队列过大，OOM，提交被拒绝方法在下面 public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get(); &#125; if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; else if (!addWorker(command, false)) // 进入拒绝机制， 我们把runnable任务拿出来，重新用阻塞操作put，来实现提交阻塞功能 reject(command); &#125; 总结： 用ThreadPoolExecutor自定义线程池，看线程是的用途，如果任务量不大，可以用无界队列，如果任务量非常大，要用有界队列，防止OOM ,尽量使用一个有界的线程池,避免线程死锁导致大量线程堆积. 如果任务量很大，还要求每个任务都处理成功，要对提交的任务进行阻塞提交，重写拒绝机制，改为阻塞提交。保证不抛弃一个任务 最大线程数一般IO密集型设为2N+1,CPU密集型N+1最好，N是CPU核数 核心线程数，看应用，如果是任务，一天跑一次，设置为0，合适，因为跑完就停掉了，如果是常用线程池，看任务量，是保留一个核心还是几个核心线程数 如果要获取任务执行结果，用CompletionService，但是注意，获取任务的结果的要重新开一个线程获取，如果在主线程获取，就要等任务都提交后才获取，就会阻塞大量任务结果，队列过大OOM，所以最好异步开个线程获取结果 自定义线程池 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112package com.lenovo.csdcodrule.util;import java.util.ArrayList;import java.util.List;import java.util.concurrent.*;import java.util.concurrent.atomic.AtomicInteger;/** * @author dcx * @description 多线程调度 * @date 2019/7/8 */public class MyThreadPoolExecutor &#123; /** * 创建一个无回调的线程池 * * @return */ public static ExecutorService newPoolService() &#123; return new ThreadPoolExecutor(3, 3, 3, TimeUnit.HOURS, new ArrayBlockingQueue&lt;Runnable&gt;(100), new MyThreadFactory(), new CustomRejectedExecutionHandler()); &#125; /** * 执行任务,具有线程回调 * * @param futureTasks */ public static void exeFutureTasks(List&lt;FutureTask&lt;Object&gt;&gt; futureTasks) &#123; ExecutorService executorService = newPoolService(); for (FutureTask&lt;Object&gt; futureTask : futureTasks) &#123; executorService.execute(futureTask); &#125; executorService.shutdown(); &#125; /** * 线程池创建工厂 */ private static class MyThreadFactory implements ThreadFactory &#123; private AtomicInteger count = new AtomicInteger(0); @Override public Thread newThread(Runnable r) &#123; Thread thread = new Thread(r); thread.setName(MyThreadPoolExecutor.class.getSimpleName() + count.addAndGet(1)); return thread; &#125; &#125; /** * 自定义堵塞策略 */ private static class CustomRejectedExecutionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; try &#123; //由blockingqueue的offer改成put阻塞方法 executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 使用 * @param args */ public static void main(String[] args) throws ExecutionException, InterruptedException &#123; //无回调,线程池使用 MyThreadPoolExecutor.newPoolService().execute(()-&gt;&#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); //带有回调的线程池使用,3个任务同时执行 FutureTask&lt;Object&gt; futureTask1 = new FutureTask&lt;&gt;(()-&gt;&#123; Thread.sleep(1000); return 1; &#125;); FutureTask&lt;Object&gt; futureTask2 = new FutureTask&lt;Object&gt;(()-&gt;&#123; Thread.sleep(1000); return 1; &#125;); FutureTask&lt;Object&gt; futureTask3 = new FutureTask&lt;Object&gt;(()-&gt;&#123; Thread.sleep(1000); return 1; &#125;); ArrayList&lt;FutureTask&lt;Object&gt;&gt; futureTasks = new ArrayList&lt;&gt;(); futureTasks.add(futureTask1); futureTasks.add(futureTask2); futureTasks.add(futureTask3); //调用方法 MyThreadPoolExecutor.exeFutureTasks(futureTasks); //堵塞创建的3个任务,拿到回调 Object result1 = futureTask1.get(); Object result2 = futureTask2.get(); Object result3 = futureTask3.get(); &#125;&#125;]]></content>
      <categories>
        <category>java基础</category>
        <category>java之线程,线程池</category>
      </categories>
      <tags>
        <tag>线程</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F02%2F28%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
